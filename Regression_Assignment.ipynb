{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###**Q1. What is Simple Linear Regression?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "Simple linear regression aims to find a linear relationship to describe the correlation between an independent and possibly dependent variable. The regression line can be used to predict or estimate missing values, this is known as interpolation.\n",
        "\n",
        "In real life example it could mean finding a relationship between the revenue and temperature, with a sample size for revenue as the dependent variable.\n",
        "\n",
        "It  is a linear regression model with a single explanatory variable.  it contains two-dimensional sample points with one independent variable and one dependent variable ( x and y coordinates) and finds a linear function (a non-vertical straight line). It predicts the dependent variable values as a function of the independent variable, as accurately as possible."
      ],
      "metadata": {
        "id": "MjHmeaT3NqFm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q2. What are the key assumptions of Simple Linear Regression?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "The key assumptions of simple linear regression are:    \n",
        "**Linearity:** The relationship between the independent variable (X) and the dependent variable (Y) is linear. If the relationship between (X) and (Y) is not linear, the predictions made by the model will be less accurate.\n",
        "\n",
        "**Homoscedasticity:** The variance of the residuals is the same for all values of (X). The spread of the residuals should be roughly the same across all values of (X).\n",
        "\n",
        "**Independence:** The observations are independent of each other. The value of (Y) for one observation should not be affected by the value of (Y) for any other observation.\n",
        "\n",
        "**Normality:** The output value of (Y) has a normal distribution for any input value of (X). The error term, or residual, in the model should follow a normal distribution\n",
        "\n",
        "**Multicollinearity:** There is no correlation between the independent variables. If the independent variables are correlated, the model will be more complex."
      ],
      "metadata": {
        "id": "I0EPVKwrPE5V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q3. What does the coefficient m represent in the equation Y=mX+c?**\n",
        "\n",
        "**Answer:**\n",
        "The coefficient **'m'** represents the slope or gradient of the line. This can be a positive slope, negative slope, or zero slope. The slope can also be calculated by the tangent of the angle of inclination of this line, with reference to the x-axis.\n",
        "\n",
        "In the below mentioned code example:\n",
        "\n",
        "1. We generate some sample data for X and y.\n",
        "2. We create a linear regression object and train it using the fit() method.\n",
        "3. We get the coefficients m and c from the trained model.\n",
        "4. We print the equation of the linear regression line in the form y = mx + c.\n",
        "5. We predict y values using the trained model and plot the data along with the linear regression line.\n",
        "\n",
        "The slope (m) represents the change in y for a one-unit change in x. In this example, the slope is approximately 1.8, indicating that for every one-unit increase in x, y increases by approximately 1.8 units."
      ],
      "metadata": {
        "id": "C6e-_SSjQkE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate some sample data\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape((-1, 1))\n",
        "y = np.array([2, 3, 5, 7, 11])\n",
        "\n",
        "# Create a linear regression object\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Get the coefficients\n",
        "m = model.coef_[0]\n",
        "c = model.intercept_\n",
        "\n",
        "print(f\"y = {m}x + {c}\")\n",
        "\n",
        "# Predict y values\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Plot the data\n",
        "plt.scatter(X, y, label=\"Data\")\n",
        "plt.plot(X, y_pred, label=\"Linear Regression Line\", color=\"red\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "8-pPm_ZbglGm",
        "outputId": "5b28095f-e448-462e-adfa-462989cd9394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y = 2.2000000000000006x + -1.0000000000000018\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAARBFJREFUeJzt3Xl8TXf+x/FXkkpiSaJRJCpIUUrsWy0d1Q1jUm1npntra6tK0Q1d1U8NWrXWboiiraqtqqhaaymxBLG0llimDTqqCSFBcn5/fCepECTce89d3s/HI49Hv/eee8/nOGPy8T7f8z1+lmVZiIiIiLiIv90FiIiIiG9R8yEiIiIupeZDREREXErNh4iIiLiUmg8RERFxKTUfIiIi4lJqPkRERMSl1HyIiIiIS91kdwGXysrK4tdffyUkJAQ/Pz+7yxEREZF8sCyLU6dOUaZMGfz9r55tuF3z8euvvxIVFWV3GSIiInIdjhw5QtmyZa+6jds1HyEhIYApPjQ01OZqREREJD9SU1OJiorK+T1+NW7XfGRfagkNDVXzISIi4mHyM2VCE05FRETEpdR8iIiIiEup+RARERGXcrs5H/lhWRYXLlwgMzPT7lJE3F5AQAA33XSTbl0XEbfhcc3HuXPnSE5O5syZM3aXIuIxihQpQmRkJIGBgXaXIiLiWc1HVlYWSUlJBAQEUKZMGQIDA/WvOZGrsCyLc+fO8dtvv5GUlETlypWvufiPiIizeVTzce7cObKysoiKiqJIkSJ2lyPiEQoXLkyhQoU4dOgQ586dIzg42O6SRMTHeeQ/gfQvN5GC0d8ZEXEnHpV8iIiIyPXLzLLYmPQ7x0+lUyokmIbR4QT4u376gpoPERERH7A4MZl+C3aRnJKe81pkWDB9Y6vRKibSpbUoixUREfFyixOT6TJ9S67GA+BoSjpdpm9hcWKyS+tR8+Ei7du3x8/PDz8/PwoVKkTp0qW5//77mTx5MllZWfn+nri4OIoXL+68QkVExKtkZln0W7ALK4/3sl/rt2AXmVl5beEcPtt8ZGZZrN9/gvkJv7B+/wmX/KG3atWK5ORkDh48yKJFi2jRogU9evTgb3/7GxcuXHD6/kVExPdsTPr9ssTjYhaQnJLOxqTfXVaTTzYfixOTaTZ4OU9M/JEeXyTwxMQfaTZ4udNjp6CgICIiIrj11lupW7cub731FvPnz2fRokXExcUBMHToUGrUqEHRokWJioripZde4vTp0wCsXLmSDh06kJKSkpOivP/++wBMmzaN+vXrExISQkREBE8++STHjx936vGIiIj7O37qyo3H9WznCD7XfLjbda977rmHWrVqMWfOHMDcEjly5Eh27tzJ1KlTWb58Ob169QKgSZMmDB8+nNDQUJKTk0lOTub1118H4Pz58/Tv359t27Yxb948Dh48SPv27V16LCIi4n5KheRvbZ/8bucIPnW3y7Wue/lhrnvdXy3CpbceVa1ale3btwPQs2fPnNcrVKjABx98wIsvvsiYMWMIDAwkLCwMPz8/IiIicn1Hx44dc/77tttuY+TIkTRo0IDTp09TrFgxlxyHiIi4n4bR4USGBXM0JT3P339+QESYue3WVXwq+XDH615glsDOXib++++/59577+XWW28lJCSEZ555hhMnTlzzWTabN28mNjaWcuXKERISQvPmzQE4fPiw0+sXERH3FeDvR9/YaoBpNC6WPe4bW82l/+j2qebDHa97AezevZvo6GgOHjzI3/72N2rWrMns2bPZvHkzo0ePBszS8leSlpZGy5YtCQ0NZcaMGcTHxzN37txrfk5ERHxDq5hIxj5dl4iw3JdWIsKCGft0XZev8+FTl13c8brX8uXL2bFjB6+88gqbN28mKyuLjz/+OGc57C+//DLX9oGBgWRmZuZ6bc+ePZw4cYJBgwYRFRUFwKZNm1xzACIi4hFaxURyf7UIrXDqanZf98rIyODo0aNkZmZy7NgxFi9ezMCBA/nb3/7Gs88+S2JiIufPn2fUqFHExsaydu1axo0bl+s7KlSowOnTp1m2bBm1atWiSJEilCtXjsDAQEaNGsWLL75IYmIi/fv3d8oxiIiI5wrw96NxxRJ2l+Fbl13svu61ePFiIiMjqVChAq1atWLFihWMHDmS+fPnExAQQK1atRg6dCiDBw8mJiaGGTNmMHDgwFzf0aRJE1588UUee+wxSpYsyYcffkjJkiWJi4tj1qxZVKtWjUGDBjFkyBCnHIOIiMiN8rMsy3VLmuVDamoqYWFhpKSkEBoamuu99PR0kpKSiI6OvqHHgrvT+vYiruCovzsiIldytd/fl/Kpyy7Z3Om6l4iIiK/xyeYD3Oe6l4iIiK/xqTkfIiIiYj81HyIiIuJSaj5ERETEpdR8iIiIiEup+RARERGXUvMhIiIiLqXmw034+fkxb948u8vwOe+//z61a9e2tYaVK1fi5+fHH3/8YWsdIiKuoubDRdq3b89DDz10xfeTk5Np3bq16woqID8/v5yf0NBQGjRowPz58+0u64a9/vrrLFu2zOn7qVChAsOHD8/zvSZNmpCcnExYWJjT6xARcQdqPtxEREQEQUFBttZgWRYXLly44vtTpkwhOTmZTZs20bRpU/7xj3+wY8cOp9Z07tw5p35/sWLFKFHC3sXmAgMDiYiIwM9PK+yKiG9Q8+EmLr7scvDgQfz8/JgzZw4tWrSgSJEi1KpVi/Xr1+f6zJo1a7jrrrsoXLgwUVFRdO/enbS0tJz3p02bRv369QkJCSEiIoInn3yS48eP57yfHfcvWrSIevXqERQUxJo1a65YY/HixYmIiOD222+nf//+XLhwgRUrVuS8f+TIER599FGKFy9OeHg4bdu25eDBgznvX7hwge7du1O8eHFKlChB7969adeuXa5E6O6776Zbt2707NmTW265hZYtWwKQmJhI69atKVasGKVLl+aZZ57hv//9b87nvvrqK2rUqEHhwoUpUaIE9913X86fxcqVK2nYsCFFixalePHiNG3alEOHDgGXX3bJysri//7v/yhbtixBQUHUrl2bxYsX57yf33NTEJdedomLi6N48eIsWbKEO+64g2LFitGqVSuSk5NzfW7SpEnccccdBAcHU7VqVcaMGXPdNYiIuJLnNx+WBWlp9vw4+Zl8b7/9Nq+//joJCQncfvvtPPHEEznJxP79+2nVqhV///vf2b59OzNnzmTNmjV069Yt5/Pnz5+nf//+bNu2jXnz5nHw4EHat29/2X769OnDoEGD2L17NzVr1rxmXRcuXODf//43YP7Vnr2vli1bEhISwg8//MDatWtzfmlmpxeDBw9mxowZTJkyhbVr15KamprnPJepU6cSGBjI2rVrGTduHH/88Qf33HMPderUYdOmTSxevJhjx47x6KOPAuaS1RNPPEHHjh3ZvXs3K1eu5JFHHslJch566CGaN2/O9u3bWb9+PS+88MIVU4YRI0bw8ccfM2TIELZv307Lli158MEH2bt3b77PjSOcOXOGIUOGMG3aNFavXs3hw4d5/fXXc96fMWMG7733HgMGDGD37t3861//4t1332Xq1KkOq0FExGksN5OSkmIBVkpKymXvnT171tq1a5d19uzZP188fdqyTBvg+p/Tp/N9XO3atbPatm17xfcBa+7cuZZlWVZSUpIFWJMmTcp5f+fOnRZg7d6927Isy+rUqZP1wgsv5PqOH374wfL398/953OR+Ph4C7BOnTplWZZlrVixwgKsefPmXbN+wAoODraKFi1q+fv7W4BVoUIF68SJE5ZlWda0adOsKlWqWFlZWTmfycjIsAoXLmwtWbLEsizLKl26tPXRRx/lvH/hwgWrXLlyuf5cmjdvbtWpUyfXvvv372898MADuV47cuSIBVg//fSTtXnzZguwDh48eFndJ06csABr5cqVeR5X3759rVq1auWMy5QpYw0YMCDXNg0aNLBeeukly7Lyd27yUr58eWvYsGF5vpd9Hk6ePGlZlmVNmTLFAqx9+/blbDN69GirdOnSOeOKFStan332Wa7v6d+/v9W4ceM895Hn3x0REQe62u/vS3l+8uHFLk4hIiMjAXIum2zbto24uDiKFSuW89OyZUuysrJISkoCYPPmzcTGxlKuXDlCQkJo3rw5AIcPH861n/r16+ernmHDhpGQkMCiRYuoVq0akyZNIjw8PKeeffv2ERISklNPeHg46enp7N+/n5SUFI4dO0bDhg1zvi8gIIB69epdtp9LX9u2bRsrVqzIdaxVq1YFTAJUq1Yt7r33XmrUqME///lPJk6cyMmTJwEIDw+nffv2tGzZktjYWEaMGHHZ5Ytsqamp/PrrrzRt2jTX602bNmX37t25XrvauXGEIkWKULFixVz7yP7+tLQ09u/fT6dOnXL9mXzwwQfs37/fYTWIiDiL5z/VtkgROH3avn07UaFChXL+O/syQVZWFgCnT5+mc+fOdO/e/bLPlStXjrS0NFq2bEnLli2ZMWMGJUuW5PDhw7Rs2fKySZxFixbNVz0RERFUqlSJSpUqMWXKFP7617+ya9cuSpUqxenTp6lXrx4zZsy47HMlS5bM9zHnVc/p06eJjY1l8ODBl20bGRlJQEAAS5cuZd26dXz33XeMGjWKt99+mw0bNhAdHc2UKVPo3r07ixcvZubMmbzzzjssXbqUO++8s0B1Xexq58YRLv7+7H1Y/7vMd/p//3ufOHEijRo1yrVdQECAw2oQEXEWz28+/Pwgn788vUndunXZtWsXlSpVyvP9HTt2cOLECQYNGkRUVBQAmzZtctj+GzZsSL169RgwYAAjRoygbt26zJw5k1KlShEaGprnZ0qXLk18fDx/+ctfAMjMzGTLli3XXGejbt26zJ49mwoVKnDTTXn/T9bPz4+mTZvStGlT3nvvPcqXL8/cuXN59dVXAahTpw516tThzTffpHHjxnz22WeXNR+hoaGUKVOGtWvX5qREAGvXrs2V2NitdOnSlClThgMHDvDUU0/ZXY6ISIF5fvPhQVJSUkhISMj1WokSJXKag4Lo3bs3d955J926deO5556jaNGi7Nq1i6VLl/LJJ59Qrlw5AgMDGTVqFC+++CKJiYn079/fQUdi9OzZk4cffphevXrx1FNP8dFHH9G2bducu0UOHTrEnDlz6NWrF2XLluXll19m4MCBVKpUiapVqzJq1ChOnjx5zVtMu3btysSJE3niiSfo1asX4eHh7Nu3jy+++IJJkyaxadMmli1bxgMPPECpUqXYsGEDv/32G3fccQdJSUlMmDCBBx98kDJlyvDTTz+xd+9enn322Tz39cYbb9C3b18qVqxI7dq1mTJlCgkJCXkmOgX1yy+/XHb+y5cvf13f1a9fP7p3705YWBitWrUiIyODTZs2cfLkyZyGS0TEXan5cKGVK1dSp06dXK916tSJSZMmFfi7atasyapVq3j77be56667sCyLihUr8thjjwHmUkdcXBxvvfUWI0eOpG7dugwZMoQHH3zQIccC0KpVK6KjoxkwYABjxoxh9erV9O7dm0ceeYRTp05x6623cu+99+YkIb179+bo0aM8++yzBAQE8MILL9CyZctrXirITiN69+7NAw88QEZGBuXLl6dVq1b4+/sTGhrK6tWrGT58OKmpqZQvX56PP/6Y1q1bc+zYMfbs2cPUqVM5ceIEkZGRdO3alc6dO+e5r+7du5OSksJrr73G8ePHqVatGl9//TWVK1e+4T+vIUOGMGTIkFyvTZs2jbJlyxb4u5577jmKFCnCRx99xBtvvEHRokWpUaMGPXv2vOE6RUSczc/KvpDsJlJTUwkLCyMlJeWy+D49PZ2kpCSio6MJDg62qUJxlKysLO644w4effRRh6cykpv+7oiIs13t9/ellHyIyxw6dIjvvvuO5s2bk5GRwSeffEJSUhJPPvmk3aWJiIgL6VZbcRl/f3/i4uJo0KABTZs2ZceOHXz//ffccccddpcmIiIuVODmY/Xq1cTGxlKmTJk8n8RqWRbvvfcekZGRFC5cmPvuu++y1SHFN0VFRbF27VpSUlJITU1l3bp1OXe+iIiI7yhw85GWlkatWrUYPXp0nu9/+OGHjBw5knHjxrFhwwaKFi1Ky5YtSU9Pv+FiRURExPMVeM5H69atr/jod8uyGD58OO+88w5t27YF4NNPP6V06dLMmzePxx9//MaqFRERkRvz7bdQogRcskihKzl0zkdSUhJHjx7lvvvuy3ktLCyMRo0aXfGpnxkZGaSmpub6uRY3u0FHxO3p74yI8Mcf0KEDtGkDzz4LZ8/aVopDm4+jR48CZgXGi5UuXTrnvUsNHDiQsLCwnJ+rLbiVveT0mTNnHFSxiG/I/jtz6bLtIuIjFi2CmBiIizMrg8fG2lqO7bfavvnmm7lWZExNTb1iAxIQEEDx4sVzHrBVpEiRa66OKeLLLMvizJkzHD9+nOLFi+vZLyK+JiUFXn0VJk8248qVYcoUuOQBmq7m0OYjIiICgGPHjuU86TN7fKXndwQFBREUFFTgfTjyCaIi3q548eI5f3dExEcsWQLPPQf/+Y9JO3r2hA8+cPpDUfPDoc1HdHQ0ERERLFu2LKfZSE1NZcOGDXTp0sUh+/Dz8yMyMpJSpUpx/vx5h3yniDcrVKiQEg8RX5KaCq+9BtmP7qhUyaQdzZrZW9dFCtx8nD59mn379uWMk5KSSEhIIDw8nHLlytGzZ08++OADKleuTHR0NO+++y5lypThoYcecmTdBAQE6P9QRURELrZ0KXTqBEeOmLSje3f417/cIu24WIGbj02bNtGiRYuccfZ8jXbt2hEXF0evXr1IS0vjhRde4I8//qBZs2YsXrxYz5MQERFxltRUeOMNmDDBjG+7zaQdbrqQo0c9WE5EREQu8f33Ju04fNiMX34ZBg6EokVdWoYeLCciIuLtTp2CXr1g3Dgzjo42d7XcfbetZeWHHiwnIiLiaZYvhxo1/mw8unaF7ds9ovEAJR8iIiKe4/Rp6N0bxowx4woVTNpx0VxMT6DmQ0RExBOsXAkdO0JSkhl36QIffgjFitla1vXQZRcRERF3lpZmJpG2aGEaj/LlYdkyk354YOMBSj5ERETc16pVJu04cMCMO3eGjz6CkBB767pBSj5ERETcTVoa9OhhJpAeOADlypkFxMaN8/jGA5R8iIiIuJcffoAOHWD/fjN+/nkYMgS8aO0rJR8iIiLu4MwZ8/C35s1N4xEVZR4ON2GCVzUeoORDRETEfmvWmLQj+9lpzz1n0o6wMHvrchIlHyIiInY5cwZefdU8g2XfPihbFhYtgokTvbbxACUfIiIi9li3Dtq3h717zbhjRxg61KubjmxKPkRERFzp7Fl4/XVo1sw0HmXKwMKF8O9/+0TjAUo+REREXGf9ejO346efzLh9exg2DIoXt7Mql1PyISIi4mzp6eYJtM2amcYjMhK++QamTPG5xgOUfIiIiDjXhg0m4dizx4yffRaGD4ebb7azKlsp+RAREXGG9HTo0weaNDGNR0QEfP01TJ3q040HKPkQERFxvPh4k3bs2mXGTz8NI0ZAeLitZbkLJR8iIiKOkpEBb74Jd95pGo/SpWHePJg2TY3HRZR8iIiIOMKmTSbt2LnTjJ98EkaOhBIlbC3LHSn5EBERuREZGfD22ybt2LkTSpWCuXNhxgw1Hleg5ENEROR6bdkC7dpBYqIZP/44jBoFt9xib11uTsmHiIhIQZ07B+++Cw0bmsajZEmYPRs+/1yNRz4o+RARESmIrVvN3I7t28340Ufhk09MAyL5ouRDREQkP86dg759TdqxfbtJOGbNgpkz1XgUkJIPERGRa0lIMGnHtm1m/M9/wujRajquk5IPERGRKzl/Hvr1gwYNTONRooRJOr78Uo3HDVDyISIikpft203asXWrGf/97zBmjLmVVm6Ikg8REZGLnT8P/ftD/fqm8QgPN3exzJqlxsNBlHyIiIhk27HDpB1btpjxww/D2LFmmXRxGCUfIiIiFy7AgAFQr55pPMLDzQqls2er8XACJR8iIuLbEhNN2rF5sxm3bQvjxkFEhK1leTMlHyIi4psuXICBA03asXkz3Hyzefrs3LlqPJxMyYeIiPieXbtM2hEfb8axsTB+PERG2lqWr1DyISIivuPCBRg8GOrUMY1H8eIwdSrMn6/Gw4WUfIiIiG/YvdukHRs3mnGbNjBhApQpY2tZvkjJh4iIeLfMTPjoI5N2bNwIYWEQFwcLFqjxsImSDxER8V579kCHDvDjj2bcujVMnAi33mpvXT5OyYeIiHifzEz4+GOoXds0HqGhMHkyLFyoxsMNKPkQERHv8vPPJu1Yt86MW7Y0aUdUlL11SQ4lHyIi4h0yM2HoUKhVyzQeISEwaRIsWqTGw80o+RAREc+3d69JO9auNeP77zeNR7ly9tYleVLyISIinisrC4YPN2nH2rUm7ZgwAZYsUePhxpR8iIiIZ9q3Dzp2hB9+MOP77oN//1tNhwdQ8iEiIp4lKwtGjoSaNU3jUayYeRDcd9+p8fAQSj5ERMRz7N9v0o7Vq834nntM2lGhgq1lScEo+RAREfeXlQWffGLSjtWroWhRGDMGli5V4+GBlHyIiIh7O3AAOnWClSvNuEULk3ZER9tallw/JR8iIuKesrJMulGzpmk8ihSB0aPh++/VeHg4JR8iIuJ+Dh40cztWrDDj5s3N8ui33WZrWeIYSj5ERMR9WJa5c6VGDdN4FCkCo0bB8uVqPLyIkg8REXEPhw6ZuR3LlpnxXXfBlClQsaK9dYnDKfkQERF7WRaMHw8xMabxKFwYRoww8zzUeHglJR8iImKfw4fhuefMLbMAzZqZtKNSJXvrEqdS8iEiIq5nWeYx9zExpvEoXBiGDTNphxoPr6fkQ0REXOvIEXj+efPwN4AmTUzacfvt9tYlLqPkQ0REXMOyzOJgMTGm8QgOho8/NiuWqvHwKQ5vPjIzM3n33XeJjo6mcOHCVKxYkf79+2NZlqN3JSIinuI//4G//tXM70hNhcaNISEBXn0VAgLsrk5czOGXXQYPHszYsWOZOnUq1atXZ9OmTXTo0IGwsDC6d+/u6N2JiIg7syyIi4NXXoGUFAgKgg8+MGM1HT7L4c3HunXraNu2LW3atAGgQoUKfP7552zcuNHRuxIREXf2yy/wwgvw7bdm3KiRaUSqVrW1LLGfwy+7NGnShGXLlvHzzz8DsG3bNtasWUPr1q3z3D4jI4PU1NRcPyIi4sEsC6ZOherVTeMRFASDB8PatWo8BHBC8tGnTx9SU1OpWrUqAQEBZGZmMmDAAJ566qk8tx84cCD9+vVzdBkiImKHX3+Fzp3hm2/MuGFDcydLtWr21iVuxeHJx5dffsmMGTP47LPP2LJlC1OnTmXIkCFMnTo1z+3ffPNNUlJScn6OHDni6JJERMTZLAumTTNpxzffQGAgDBxo0g41HnIJP8vBt6FERUXRp08funbtmvPaBx98wPTp09mzZ881P5+amkpYWBgpKSmEhoY6sjQREXGG5GSTdixYYMb165u5HdWr21qWuFZBfn87PPk4c+YM/v65vzYgIICsrCxH70pEROxkWTBjhmkyFiyAQoVgwABYv16Nh1yVw+d8xMbGMmDAAMqVK0f16tXZunUrQ4cOpWPHjo7elYiI2OXoUXjxRZg/34zr1TNpR0yMrWWJZ3D4ZZdTp07x7rvvMnfuXI4fP06ZMmV44okneO+99wgMDLzm53XZRUTEjVkWfPEFdOsGv/9u0o733oPevc1/i88qyO9vhzcfN0rNh4iImzp2DF56CebMMeM6dUzaUbOmrWWJe7B1zoeIiHgZy4KZM808jjlz4KaboF8/2LBBjYdcFz3VVkREruz4cZN2zJ5txrVrm7SjVi07qxIPp+RDRETyNmuWSTtmzzZpx/vvw8aNajzkhin5EBGR3H77Dbp2Nc0HmEsrU6ea1EPEAZR8iIjIn776yqQds2aZp86+9x7Ex6vxEIdS8iEiIvDf/5rbZ2fONOMaNczcjrp1bS1LvJOSDxERXzdnjkk7Zs40acc778CmTWo8xGmUfIiI+KoTJ+Dll+Hzz824enUzt6NePXvrEq+n5ENExBfNm2eajc8/N2nHW2/B5s1qPMQllHyIiPiSEyege3f47DMzrlbNzO1o0MDWssS3KPkQEfEVX39tHvz22Wfg7w99+pi0Q42HuJiSDxERb/f779CjB0yfbsZVq5q5HQ0b2luX+CwlHyIi3uybb0zaMX26STt69YKtW9V4iK2UfIiIeKOTJ6FnT/j0UzOuWhWmTIE777S1LBFQ8iEi4n0WLjRpx6efgp8fvPEGbNmixkPchpIPERFv8ccf8Mor5u4VgNtvN//duLGNRYlcTsmHiIg3WLTIpB1xcSbteO01SEhQ4yFuScmHiIgnS0mBV1+FyZPNuHJlM7ejaVN76xK5CiUfIiKeaskSk3ZMnmzSjldeMWmHGg9xc0o+REQ8TWqquawyaZIZV6pk0o5mzeytSySflHyIiHiSpUtN2jFpkkk7evSAbdvUeIhHUfIhIuIJUlPNLbMTJpjxbbeZtOMvf7G3LpHroORDRMTdff891KjxZ+Px8suwfbsaD/FYSj5ERNzVqVNmOfRx48w4OtpMLr37blvKycyy2Jj0O8dPpVMqJJiG0eEE+PvZUot4NjUfIiLuaPly6NgRDh0y465dYdAgKFbMlnIWJybTb8EuklPSc16LDAumb2w1WsVE2lKTeC5ddhERcSenT5tG4957TeNRoYJpRD75xNbGo8v0LbkaD4CjKel0mb6FxYnJttQlnkvNh4iIu1i5EmrWhDFjzLhLF9ixA1q0sK2kzCyLfgt2YeXxXvZr/RbsIjMrry1E8qbmQ0TEbmlpZhJpixaQlATly5tJpmPG2JZ2ZNuY9PtlicfFLCA5JZ2NSb+7rijxeJrzISJip1WrzNyOAwfMuHNn+OgjCAmxt67/OX7qyo3H9WwnAko+RETskZYG3bubO1cOHICoKPjuO3Nni5s0HgClQoIdup0IqPkQEXG9H36AWrVg1Cgzfv55SEyE+++3t648NIwOJzIsmCvdUOuHueulYXS4K8sSD6fmQ0TEVc6cgZ49oXlz2L/fpB1LlpjFw0JD7a4uTwH+fvSNrQZwWQOSPe4bW03rfUiBqPkQEXGFNWtM2jFiBFgWdOpk7mR54AG7K7umVjGRjH26LhFhuS+tRIQFM/bpulrnQwpME05FRJzpzBl45x0YPtw0Hbfeah4K16qV3ZUVSKuYSO6vFqEVTsUh1HyIiDjLunXQvj3s3WvGHTrA0KFQvLidVV23AH8/GlcsYXcZ4gV02UVExNHOnoXXXzePud+7F8qUgYULzXNZPLTxEHEkJR8iIo60fr1JOH76yYzbtYNhw+Dmm+2tS8SNKPkQEXGE9HTzBNpmzUzjERkJ33wDcXFqPEQuoeRDRORGbdhg5nbs2WPGzz5rJpiq6RDJk5IPEZHrlZ4OvXtDkyam8YiIgK+/hqlT1XiIXIWSDxGR6xEfb+Zz7N5txk8/bdbwCNdKnyLXouRDRKQgMjLgzTfhzjtN41G6NMybB9OmqfEQySclHyIi+bVpk5nbsXOnGT/5JIwcCSW09oVIQSj5EBG5lowMePttk3bs3AmlSsGcOTBjhhoPkeug5ENE5Go2bzZpR2KiGT/+uHka7S232FqWiCdT8iEikpdz5+Ddd6FRI9N4lCwJX30Fn3+uxkPkBin5EBG51JYtJu3YscOMH30UPvnENCAicsOUfIiIZDt3Dvr2NWnHjh0m4fjyS5g5U42HiAMp+RARAUhIMGnHtm1m/I9/wOjRZnKpiDiUkg8R8W3nz0O/ftCggWk8SpQwScesWWo8RJxEyYeI+K5t20zakZBgxo88AmPGmIXDRMRplHyIiO85fx769zdpR0KCWZn088/N3SxqPEScTsmHiPiWHTtM2rFlixk/9BCMHWseCiciLqHkQ0R8w4ULMGAA1KtnGo+bbzYrlM6Zo8ZDxMWUfIiI90tMNGnH5s1m/OCDMG4cREbaWpaIr1LyISLe68IFGDjQpB2bN5u0Y9o08xRaNR4itlHyISLeadcuk3bEx5txbCyMH6+mQ8QNKPkQEe9y4QIMHgx16pjGo3hxmDoV5s9X4yHiJpzSfPzyyy88/fTTlChRgsKFC1OjRg02bdrkjF2JiPxp925o2hT69DFLpbdpY+Z7PPss+PnZXZ2I/I/DL7ucPHmSpk2b0qJFCxYtWkTJkiXZu3cvN998s6N3JSJiZGbCxx/De+9BRgaEhcHw4dCunZoOETfk8OZj8ODBREVFMWXKlJzXoqOjHb0bERFjzx7o0AF+/NGMW7eGCROgbFl76xKRK3L4ZZevv/6a+vXr889//pNSpUpRp04dJk6ceMXtMzIySE1NzfUjInJNmZkwZAjUrm0aj9BQ+Pe/YeFCNR4ibs7hzceBAwcYO3YslStXZsmSJXTp0oXu3bszderUPLcfOHAgYWFhOT9RUVGOLklEvM3PP8Ndd8Ebb5jLLC1bmrkdHTvqMouIB/CzLMty5BcGBgZSv3591q1bl/Na9+7diY+PZ/369Zdtn5GRQUZGRs44NTWVqKgoUlJSCA0NdWRpIuLpMjNhxAh4+21IT4eQEBg6FDp1UtMhYrPU1FTCwsLy9fvb4XM+IiMjqVatWq7X7rjjDmbPnp3n9kFBQQQFBTm6DBHxNj//bJKNtWvN+P77YdIkKFfO3rpEpMAcftmladOm/PTTT7le+/nnnylfvryjdyUiviAry9y5UquWaTyKFTOLhS1ZosZDxEM5PPl45ZVXaNKkCf/617949NFH2bhxIxMmTGDChAmO3pWIeLt9+8ydLGvWmPG995pJpfrHjIhHc3jy0aBBA+bOncvnn39OTEwM/fv3Z/jw4Tz11FOO3pWIeKusLBg5EmrWNI1HsWLmsfdLl6rxEPECDp9weqMKMmFFRLzQ/v1mbsfq1WZ8zz0m7ahQwdayROTqCvL7W892ERH3kJUFo0aZtGP1aihaFMaMMWmHGg8Rr6Kn2oqI/Q4cMGnHqlVmfPfdMHkyaHVkEa+k5ENE7JOVBaNHm7Rj1SooUgQ++QSWLVPjIeLFlHyIiD0OHjRpx4oVZvyXv5i0o2JFW8sSEedT8iEirpWVZe5ciYkxjUeRIubOlhUr1HiI+AglHyLiOocOmaXQly0z47vugilT1HSI+BglHyLifJZlViWNiTGNR+HCZtXSlSvVeIj4ICUfIuJchw/Dc8+ZW2YBmjY1aUflyvbWJSK2UfIhIs5hWTBxokk7li6F4GDzBNpVq9R4iPg4JR8i4nhHjsDzz5uHvwE0aWLSjttvt7cuEXELSj5ExHEsyyyFHhNjGo/gYBgyxKxYqsZDRP5HyYeIOMZ//mPSjsWLzfjOOyEuDqpUsbUsEXE/Sj5E5MZYlrmkEhNjGo+gIPjoI/M0WjUeIpIHJR8icv1++QVeeAG+/daMGzUyjcgdd9hbl4i4NSUfIlJwlgVTp0L16qbxCAyEwYNN2qHGQ0SuQcmHiBTMr7+atGPhQjNu0MDM7ahWzdayRMRzKPkQkfyxLJg2zaQdCxeatGPgQFi3To2HiBSIkg8RubbkZOjcGRYsMON69f687CIiUkBKPkTkyiwLZswwTcaCBVCoEAwYAD/+qMZDRK6bkg8RydvRo/DiizB/vhnXrWvmdtSoYWtZIuL5lHyISG6WBZ99ZpKN+fNN2tG/v0k71HiIiAMo+RCRPx07Bl26wNy5Zlynjkk7ata0tSwR8S5qPkTEpB0zZ0K3bnDiBNx0E7z7Lrz5pkk+HCAzy2Jj0u8cP5VOqZBgGkaHE+Dv55DvFhHPouZDxNcdPw4vvQSzZ5tx7dom7ahVy2G7WJyYTL8Fu0hOSc95LTIsmL6x1WgVE+mw/YiIZ9CcDxFf9uWXZm7H7Nkm7ejbFzZscHjj0WX6llyNB8DRlHS6TN/C4sRkh+1LRDyDmg8RX/Tbb/DPf8Jjj8F//2vmdMTHw/vvm8XDHCQzy6Lfgl1YebyX/Vq/BbvIzMprCxHxVmo+RHzNV1+ZtOOrryAgwMztiI83l1scbGPS75clHhezgOSUdDYm/e7wfYuI+9KcDxFf8d//Qteu5lILmNtm4+LM+h1OcvzUlRuP69lORLyDkg8RXzBnjkk7vvzSpB1vv23SDic2HgClQoIdup2IeAclHyLe7MQJc/vsF1+YcfXqJu2oX98lu28YHU5kWDBHU9LznPfhB0SEmdtuRcR3KPkQ8VZz55qnzX7xBfj7w1tvwebNLms8AAL8/egba554e+mKHtnjvrHVtN6HiI9R8yHibU6cgKeegkceMWt4VKtmlkYfMACCglxeTquYSMY+XZeIsNyXViLCghn7dF2t8yHig3TZRcSbzJ8PnTubZdL9/aFXL7N2R7C9cypaxURyf7UIrXAqIoCaDxHv8Pvv0KMHTJ9uxlWrmrkdjRrZWtbFAvz9aFyxhN1liIgb0GUXEU+3YAHExJjGIzvt2LrVrRoPEZGLKfkQ8VQnT0LPnvDpp2ZcpYpJO+68086qRESuScmHiCdauNCkHZ9+Cn5+8PrrJu1Q4yEiHkDJh4gn+eMPeOUVk3AA3H47TJkCTZrYWZWISIEo+RDxFIsWmbQjLs6kHa++CgkJajxExOMo+RBxdykpptGYPNmMK1c2aUfTpvbWJSJynZR8iLizJUtM2jF5skk7XnnFpB1qPETEgyn5EHFHqanw2mswaZIZV6pkGpC77rK3LhERB1DyIeJuvvvOpB3ZjUePHrBtmxoPEfEaSj5E3EVqqrllduJEM77tNjO34y9/sbcuEREHU/Ih4g6+/x5q1Piz8Xj5Zdi+XY2HiHglJR8idjp1Ct54A8aPN+PoaDO34+67bS1LRMSZlHyI2GX5cpN2ZDceXbuatEONh4h4OSUfIq52+rR5+NvYsWZcoYJJO1q0sLUsERFXUfIh4korVpi0I7vx6NLFpB1qPETEh6j5EHGF06ehWze45x44eBDKlzeTTMeMgZAQu6sTEXEpXXYRcbZVq6BDB0hKMuPOneGjj9R0iIjPUvIh4ixpadC9u5lAmpQEUVFmAbFx49R4iIhPU/Ih4gyrV0PHjrB/vxk//zwMGQKhofbWJSLiBpR8iDjSmTPQs6dJO/bvh7JlYfFimDBBjYeIyP8o+RBxlDVrzNyOffvMuFMn+PhjCAuzty4RETej5EPkRp05A6++apZC37cPbr0VFi0yD4ZT4yEichklHyI3Yt06aN8e9u414w4dYOhQKF7czqpERNya05OPQYMG4efnR8+ePZ29KxHXOXsWXnsNmjUzjUeZMrBwoVmpVI2HiMhVOTX5iI+PZ/z48dSsWdOZuxFxrfXrTdrx889m3K4dDBsGN99sa1kiIp7CacnH6dOneeqpp5g4cSI36/+UxRucPWueQNusmWk8IiPhm28gLk6Nh4hIATit+ejatStt2rThvvvuu+p2GRkZpKam5voRcTsbNkDdumatjqwsePZZ2LkT2rSxuzIREY/jlMsuX3zxBVu2bCE+Pv6a2w4cOJB+/fo5owyRG5eeDn37/tl0RESYNTtiY+2uTETEYzk8+Thy5Ag9evRgxowZBAcHX3P7N998k5SUlJyfI0eOOLokkeuzcaNJOz780DQeTz9t0g41HiIiN8TPsizLkV84b948Hn74YQICAnJey8zMxM/PD39/fzIyMnK9d6nU1FTCwsJISUkhVCtCih0yMuD99/9sOkqXhvHjoW1buysTEXFbBfn97fDLLvfeey87duzI9VqHDh2oWrUqvXv3vmrjIWK7+HhzJ8uuXWb85JMwciSUKGFrWSIi3sThzUdISAgxMTG5XitatCglSpS47HURt5GRAf/3fzB4MGRmQqlS5umzDz9sd2UiIl5HK5yKbN5s0o7ERDN+/HEYNQpuucXWskREvJVLmo+VK1e6YjciBXPuHPTvDwMHmrSjZEkYOxb+/ne7KxMR8WpKPsQ3bdli0o7s+UmPPgqffGIaEBERcSo91VZ8y7lzZt2ORo1M43HLLTBrFsycqcZDRMRFlHyI70hIMGnHtm1m/I9/wOjRZnKpiIi4jJIP8X7nz0O/ftCggWk8SpQwScesWWo8RERsoORDvNu2bSbtSEgw40cegTFjzMJhIiJiCyUf4p3Onzd3stSvbxqP8HD4/HP46is1HiIiNlPyId5nxw6TdmzZYsYPP2xuoVXTISLiFpR8iPe4cAEGDIB69UzjcfPNMGMGzJ6txkNExI0o+RDvkJho0o7Nm824bVuzPHpEhK1liYjI5ZR8iGe7cMGsUFqvnmk8br4Zpk2DuXPVeIiIuCklH+K5du0yaUd8vBnHxsL48RAZaWtZIiJydUo+xPNcuACDBkGdOqbxKF4cpk6F+fPVeIiIeAAlH+JZdu82acfGjWbcpg1MmABlythaloiI5J+SD/EMmZnw4Ycm7di4EcLCYMoUWLBAjYeIiIdR8iHub88e6NABfvzRjFu3hokT4dZb7a1LRESui5IPcV+ZmTBkCNSubRqP0FD4979h4UI1HiIiHkzJh7inn34yacf69WbcsqVJO6Ki7K1LRERumJIPcS+ZmTB0qEk71q+HkBCYNAkWLVLjISLiJZR8iPv4+Wfo2BHWrjXj++83jUe5cvbWJSIiDqXkQ+yXlQXDh0OtWqbxCAkxt88uWaLGQ0TECyn5EHvt22fmdqxZY8b33WfSjvLl7a1LREScRsmH2CMrC0aOhJo1TeNRrJh5ENx336nxEBHxcko+xPX27zdzO1avNuN77jG30FaoYGtZIiLiGmo+xHWysmD0aOjTB86cgaJF4aOPoHNn8L92CJeZZbEx6XeOn0qnVEgwDaPDCfD3c0HhIiLiSGo+xDUOHDBpx6pVZtyihUk7oqPz9fHFicn0W7CL5JT0nNciw4LpG1uNVjF6mJyIiCfRnA9xruy0o2ZN03gUKQKffALff1+gxqPL9C25Gg+AoynpdJm+hcWJyc6oXEREnETNhzjPwYPm7pVu3SAtDZo3hx07oGvXfF1mAXOppd+CXVh5vJf9Wr8Fu8jMymsLERFxR2o+xPGysmDsWIiJgRUrTNoxciQsXw633Vagr9qY9PtlicfFLCA5JZ2NSb/fYNEiIuIqmvMhjnXoEHTqBMuWmfFdd8GUKVCx4nV93fFTV248rmc7ERGxn5IPcQzLgvHjTdqxbBkULgwjRsDKldfdeACUCgl26HYiImI/JR9y4w4fhueeg6VLzbhZM5g8GSpXvuGvbhgdTmRYMEdT0vOc9+EHRISZ225FRMQzKPmQ62dZ5jH3MTGm8QgOhmHDTNrhgMYDIMDfj76x1QDTaFwse9w3tprW+xAR8SBqPuT6HDkCrVvDCy/AqVPQpAls2wY9e0JAgEN31SomkrFP1yUiLPellYiwYMY+XVfrfIiIeBhddpGCsSxzSeXVVyE11aQdAwZAjx4Obzou1iomkvurRWiFUxERL6DmQ/LvP/+B55+HxYvN+M47IS4OqlRxye4D/P1oXLGES/YlIiLOo8sucm2WZW6XjYkxjUdQkHkmy5o1Lms8RETEeyj5kKv75Rczr+Pbb824USOTdlStamtZIiLiuZR8SN4sC6ZOherVTeMRFASDB5u0Q42HiIjcACUfcrlffzVpx8KFZtywobnsUq2avXWJiIhXUPIhf7IsmDbNpB0LF0JgIAwcCGvXqvEQERGHUfIhRnIydO4MCxaYcf36Zm5H9eq2liUiIt5HyYevsyyYMcM0GQsWQKFCZt2O9evVeIiIiFMo+fBlR4/Ciy/C/PlmXK+eSTtiYmwtS0REvJuSD19kWfD55ybZmD/fpB39+5u0Q42HiIg4mZIPX3PsGHTpAnPnmnGdOibtqFnT1rJERMR3KPnwFZYFM2eatGPuXLjpJujXDzZsUOMhIiIupeTDFxw/Di+9BLNnm3Ht2ibtqFXLzqpERMRHKfnwdl9+adKO2bNN2tG3r0k71HiIiIhNlHx4q99+g65dYdYsM65Z0yyXXru2rWWJiIgo+fBGX31l0o5ZsyAgAN57D+Lj1XiIiIhbUPLhTf77X+jWzUwsBahRw8ztqFvX1rJEREQupuTDW8yZY9KOmTNN2vHOO7BpkxoPERFxO0o+PN2JE/Dyy2bRMDANSFyceTaLiIiIG1Ly4cnmzTPNxuefg78/vPUWbN6sxkNERNyakg9PdOIEdO8On31mxtWqmbSjQQNbyxIREckPJR+e5uuvzfNXPvvMpB19+pi0Q42HiIh4CCUfnuL336FHD5g+3YyrVjXrdjRsaG9dIiIiBeQzzUdmlsXGpN85fiqdUiHBNIwOJ8Dfz+6y8uebb+CFFyA52aQdr79unssSHGx3ZSIiIgXm8OZj4MCBzJkzhz179lC4cGGaNGnC4MGDqVKliqN3lW+LE5Ppt2AXySnpOa9FhgXTN7YarWIibavrmk6ehJ494dNPzbhKFTO348477axKRETkhjh8zseqVavo2rUrP/74I0uXLuX8+fM88MADpKWlOXpX+bI4MZku07fkajwAjqak02X6FhYnJttS1zV9+62Z2/Hpp+DnZ9KOrVvVeIiIiMfzsyzLcuYOfvvtN0qVKsWqVav4y1/+cs3tU1NTCQsLIyUlhdDQ0Bvad2aWRbPByy9rPLL5ARFhwazpfY/7XIL54w945RWTcADcfrv578aNbSxKRETk6gry+9vpd7ukpKQAEB4enuf7GRkZpKam5vpxlI1Jv1+x8QCwgOSUdDYm/e6wfd6QRYtM2hEXZ9KO116DhAQ1HiIi4lWc2nxkZWXRs2dPmjZtSkxMTJ7bDBw4kLCwsJyfqKgoh+3/+KkrNx7Xs53TpKRAp07w17/CL79A5crwww8wZAgULmxvbSIiIg7m1Oaja9euJCYm8sUXX1xxmzfffJOUlJScnyNHjjhs/6VC8nc3SH63c4olS0zaMXmySTteecWkHU2b2leTiIiIEzntVttu3brxzTffsHr1asqWLXvF7YKCgggKCnJKDQ2jw4kMC+ZoSjp5TWzJnvPRMDrvS0JOlZpqLqtMmmTGlSqZBuSuu1xfi4iIiAs5PPmwLItu3boxd+5cli9fTnR0tKN3kW8B/n70ja0GmEbjYtnjvrHVXD/ZdOlSk3ZMmmTSjh49YNs2NR4iIuITHN58dO3alenTp/PZZ58REhLC0aNHOXr0KGfPnnX0rvKlVUwkY5+uS0RY7ksrEWHBjH26rmvX+UhNhc6d4YEH4MgRuO02WLkShg+HIkVcV4eIiIiNHH6rrZ9f3inClClTaN++/TU/78hbbS9m+wqn339vJpUePmzGL78MAwdC0aKuq0FERMRJCvL72+FzPpy8bMh1C/D3o3HFEq7f8alT0KsXjBtnxtHRZm7H3Xe7vhYRERE3oKfaOtPy5VCjxp+NR9eusH27Gg8REfFpPvNgOZc6fRp694YxY8y4QgWTdrRoYWtZIiIi7kDNh6OtXAkdO0JSkhl36QIffgjFitlaloiIiLvQZRdHSUszk0hbtDCNR/nyZpLpmDFqPERERC6i5MMRVq0yaceBA2bcuTN89BGEhNhbl4iIiBtS8nEj0tLMAmF3320aj6go+O47M8FUjYeIiEielHxcrx9+gA4dYP9+M37+efMgOAeuTSIiIuKNlHwU1Jkz5uFvzZubxiMqyjwcbsIENR4iIiL5oOSjINauNWnH3r1m3KkTfPwxhIXZW5eIiIgHUfKRH2fPmifQ3nWXaTxuvRUWLTIPhlPjISIiUiBKPq5l3TqTdvz8sxl36ABDh0Lx4raWJSIi4qmUfFzJ2bPw+uvQrJlpPMqUgYULzUqlajxERESum5KPvPz4I7RvDz/9ZMbt2sGwYXDzzbaWJSIi4g2UfFwsPd08gbZpU9N4REbCN99AXJwaDxEREQdR8pFtwwaTduzZY8bPPgvDh6vpEBERcTAlH+np0KcPNGliGo+ICPj6a5g6VY2HiIiIE/h28hEfb9KOXbvM+OmnYcQICA+3tSwRERFv5pvJR0YGvPUW3HmnaTxKl4Z582DaNDUeIiIiTuZ7ycemTSbt2LnTjJ98EkaOhBIlbC1LRETEV/hO8pGRAe+8Y9KOnTuhVCmYMwdmzFDjISIi4kK+03wsXgwDBkBmJjz+uGlAHn7Y7qpERER8ju9cdnnwQXjhBXjgAfj73+2uRkRExGf5TvPh5wfjx9tdhYiIiM/zncsuIiIi4hbUfIiIiIhLqfkQERERl1LzISIiIi6l5kNERERcSs2HiIiIuJSaDxEREXEpNR8iIiLiUmo+RERExKXUfIiIiIhLqfkQERERl1LzISIiIi6l5kNERERcyu2eamtZFgCpqak2VyIiIiL5lf17O/v3+NW4XfNx6tQpAKKiomyuRERERArq1KlThIWFXXUbPys/LYoLZWVl8euvvxISEoKfn59Dvzs1NZWoqCiOHDlCaGioQ7/bHXj78YH3H6OOz/N5+zHq+Dyfs47RsixOnTpFmTJl8Pe/+qwOt0s+/P39KVu2rFP3ERoa6rX/owLvPz7w/mPU8Xk+bz9GHZ/nc8YxXivxyKYJpyIiIuJSaj5ERETEpXyq+QgKCqJv374EBQXZXYpTePvxgfcfo47P83n7Mer4PJ87HKPbTTgVERER7+ZTyYeIiIjYT82HiIiIuJSaDxEREXEpNR8iIiLiUl7TfKxevZrY2FjKlCmDn58f8+bNu+ZnVq5cSd26dQkKCqJSpUrExcU5vc4bUdBjXLlyJX5+fpf9HD161DUFF9DAgQNp0KABISEhlCpVioceeoiffvrpmp+bNWsWVatWJTg4mBo1avDtt9+6oNqCu57ji4uLu+z8BQcHu6jighk7diw1a9bMWbiocePGLFq06Kqf8ZRzl62gx+hJ5y8vgwYNws/Pj549e151O087j9nyc3yedg7ff//9y+qtWrXqVT9jx/nzmuYjLS2NWrVqMXr06Hxtn5SURJs2bWjRogUJCQn07NmT5557jiVLlji50utX0GPM9tNPP5GcnJzzU6pUKSdVeGNWrVpF165d+fHHH1m6dCnnz5/ngQceIC0t7YqfWbduHU888QSdOnVi69atPPTQQzz00EMkJia6sPL8uZ7jA7MK4cXn79ChQy6quGDKli3LoEGD2Lx5M5s2beKee+6hbdu27Ny5M8/tPencZSvoMYLnnL9LxcfHM378eGrWrHnV7TzxPEL+jw887xxWr149V71r1qy54ra2nT/LCwHW3Llzr7pNr169rOrVq+d67bHHHrNatmzpxMocJz/HuGLFCguwTp486ZKaHO348eMWYK1ateqK2zz66KNWmzZtcr3WqFEjq3Pnzs4u74bl5/imTJlihYWFua4oB7v55putSZMm5fmeJ5+7i13tGD31/J06dcqqXLmytXTpUqt58+ZWjx49rritJ57Hghyfp53Dvn37WrVq1cr39nadP69JPgpq/fr13Hfffblea9myJevXr7epIuepXbs2kZGR3H///axdu9bucvItJSUFgPDw8Ctu48nnMT/HB3D69GnKly9PVFTUNf+V7S4yMzP54osvSEtLo3Hjxnlu48nnDvJ3jOCZ569r1660adPmsvOTF088jwU5PvC8c7h3717KlCnDbbfdxlNPPcXhw4evuK1d58/tHiznKkePHqV06dK5XitdujSpqamcPXuWwoUL21SZ40RGRjJu3Djq169PRkYGkyZN4u6772bDhg3UrVvX7vKuKisri549e9K0aVNiYmKuuN2VzqO7zmvJlt/jq1KlCpMnT6ZmzZqkpKQwZMgQmjRpws6dO53+AMbrsWPHDho3bkx6ejrFihVj7ty5VKtWLc9tPfXcFeQYPe38AXzxxRds2bKF+Pj4fG3vaeexoMfnaeewUaNGxMXFUaVKFZKTk+nXrx933XUXiYmJhISEXLa9XefPZ5sPX1ClShWqVKmSM27SpAn79+9n2LBhTJs2zcbKrq1r164kJiZe9VqlJ8vv8TVu3DjXv6qbNGnCHXfcwfjx4+nfv7+zyyywKlWqkJCQQEpKCl999RXt2rVj1apVV/zl7IkKcoyedv6OHDlCjx49WLp0qVtPqrxe13N8nnYOW7dunfPfNWvWpFGjRpQvX54vv/ySTp062VhZbj7bfERERHDs2LFcrx07dozQ0FCvSD2upGHDhm7/C71bt2588803rF69+pr/srjSeYyIiHBmiTekIMd3qUKFClGnTh327dvnpOpuTGBgIJUqVQKgXr16xMfHM2LECMaPH3/Ztp547qBgx3gpdz9/mzdv5vjx47mS0czMTFavXs0nn3xCRkYGAQEBuT7jSefxeo7vUu5+Di9VvHhxbr/99ivWa9f589k5H40bN2bZsmW5Xlu6dOlVr916g4SEBCIjI+0uI0+WZdGtWzfmzp3L8uXLiY6OvuZnPOk8Xs/xXSozM5MdO3a47Tm8VFZWFhkZGXm+50nn7mqudoyXcvfzd++997Jjxw4SEhJyfurXr89TTz1FQkJCnr+YPek8Xs/xXcrdz+GlTp8+zf79+69Yr23nz6nTWV3o1KlT1tatW62tW7dagDV06FBr69at1qFDhyzLsqw+ffpYzzzzTM72Bw4csIoUKWK98cYb1u7du63Ro0dbAQEB1uLFi+06hGsq6DEOGzbMmjdvnrV3715rx44dVo8ePSx/f3/r+++/t+sQrqpLly5WWFiYtXLlSis5OTnn58yZMznbPPPMM1afPn1yxmvXrrVuuukma8iQIdbu3butvn37WoUKFbJ27NhhxyFc1fUcX79+/awlS5ZY+/fvtzZv3mw9/vjjVnBwsLVz5047DuGq+vTpY61atcpKSkqytm/fbvXp08fy8/OzvvvuO8uyPPvcZSvoMXrS+buSS+8G8YbzeLFrHZ+nncPXXnvNWrlypZWUlGStXbvWuu+++6xbbrnFOn78uGVZ7nP+vKb5yL6t9NKfdu3aWZZlWe3atbOaN29+2Wdq165tBQYGWrfddps1ZcoUl9ddEAU9xsGDB1sVK1a0goODrfDwcOvuu++2li9fbk/x+ZDXsQG5zkvz5s1zjjfbl19+ad1+++1WYGCgVb16dWvhwoWuLTyfruf4evbsaZUrV84KDAy0Spcubf31r3+1tmzZ4vri86Fjx45W+fLlrcDAQKtkyZLWvffem/NL2bI8+9xlK+gxetL5u5JLfzl7w3m82LWOz9PO4WOPPWZFRkZagYGB1q233mo99thj1r59+3Led5fz52dZluXcbEVERETkTz4750NERETsoeZDREREXErNh4iIiLiUmg8RERFxKTUfIiIi4lJqPkRERMSl1HyIiIiIS6n5EBEREZdS8yEiIiIupeZDREREXErNh4iIiLiUmg8RERFxqf8HlD8vwyvdpJMAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above graph shows the equation of the line y = mx + c, where m is the slope of the line, and c is the y-intercept of the line. This line cuts the y-axis at the point (0, c) which is at a distance of c units from the origin. The inclination of this line with reference to the x-axis or a line parallel to the x-axis is known by its slope m value."
      ],
      "metadata": {
        "id": "o505vmFyhomo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q4. What does the intercept c represent in the equation Y=mX+c?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "Below is  an example of how to interpret the intercept c:\n"
      ],
      "metadata": {
        "id": "ehxxNqPMlCeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate some sample data\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape((-1, 1))\n",
        "y = np.array([2, 3, 5, 7, 11])\n",
        "\n",
        "# Create a linear regression object\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Get the coefficients\n",
        "m = model.coef_[0]\n",
        "c = model.intercept_\n",
        "\n",
        "print(f\"y = {m}x + {c}\")\n",
        "\n",
        "# Predict y values\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Plot the data\n",
        "plt.scatter(X, y, label=\"Data\")\n",
        "plt.plot(X, y_pred, label=\"Linear Regression Line\", color=\"red\")\n",
        "plt.axhline(y=c, color='green', linestyle='--', label='Intercept')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "jhLCKTtxtAYm",
        "outputId": "231e7e92-3b43-4672-c7ab-e047c48ac142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y = 2.2000000000000006x + -1.0000000000000018\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above example:\n",
        "\n",
        "- We generate some sample data for X and y.\n",
        "- We create a linear regression object and train it using the fit() method.\n",
        "- We get the coefficients m and c from the trained model.\n",
        "- We print the equation of the linear regression line in the form y = mx + c.\n",
        "- We predict y values using the trained model and plot the data along with the linear regression line.\n",
        "- We use axhline() to draw a horizontal line representing the intercept c.\n"
      ],
      "metadata": {
        "id": "6anPArSCtOqq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q5. How do we calculate the slope m in Simple Linear Regression?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "The slope (m) in Simple Linear Regression can be calculated using the following formula:\n",
        "\n",
        "m = (n * Σ(xy) - Σx * Σy) / (n * Σx^2 - (Σx)^2)\n",
        "\n",
        "Where:\n",
        "\n",
        "- m is the slope of the regression line\n",
        "- n is the number of observations\n",
        "- x is the independent variable\n",
        "- y is the dependent variable\n",
        "- Σxy is the sum of the products of x and y\n",
        "- Σx is the sum of the x values\n",
        "- Σy is the sum of the y values\n",
        "- Σx^2 is the sum of the squares of the x values\n"
      ],
      "metadata": {
        "id": "Ema50dsKtlca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the data\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([2, 3, 5, 7, 11])\n",
        "\n",
        "# Calculate the necessary sums\n",
        "n = len(x)\n",
        "sum_x = np.sum(x)\n",
        "sum_y = np.sum(y)\n",
        "sum_xy = np.sum(x * y)\n",
        "sum_x_squared = np.sum(x ** 2)\n",
        "\n",
        "# Calculate the slope (m)\n",
        "m = (n * sum_xy - sum_x * sum_y) / (n * sum_x_squared - sum_x ** 2)\n",
        "\n",
        "print(\"The slope (m) is:\", m)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amLuKJFBo9VW",
        "outputId": "8818a749-c3c1-48c7-fc0c-5f2aa61a83c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slope (m) is: 2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q6. What is the purpose of the least squares method in Simple Linear Regression?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "The purpose of the least squares method in Simple Linear Regression is to find the best-fitting line that minimizes the sum of the squared errors (SSE) between the observed data points and the predicted values.\n",
        "\n",
        "The least squares method works by iteratively adjusting the coefficients of the linear equation (slope and intercept) to minimize the SSE. The goal is to find the values of the coefficients that result in the smallest possible SSE.\n",
        "\n",
        "The least squares method serves several purposes in Simple Linear Regression:\n",
        "\n",
        "1. Parameter estimation: The least squares method provides estimates of the slope and intercept of the linear regression line.\n",
        "2. Model fitting: The least squares method helps to find the best-fitting line that describes the relationship between the independent variable (x) and the dependent variable (y).\n",
        "3. Error minimization: The least squares method minimizes the sum of the squared errors (SSE) between the observed data points and the predicted values.\n",
        "4. Optimization: The least squares method optimizes the coefficients of the linear equation to achieve the best possible fit to the data.\n",
        "\n",
        "The advantages of the least squares method include:\n",
        "\n",
        "1. Unbiasedness: The least squares method provides unbiased estimates of the parameters.\n",
        "2. Efficiency: The least squares method is computationally efficient and can handle large datasets.\n",
        "3. Robustness: The least squares method is robust to minor deviations from the assumptions of linear regression.\n",
        "\n",
        "However, the least squares method assumes that the data meet certain conditions, such as:\n",
        "\n",
        "1. Linearity: The relationship between x and y is linear.\n",
        "2. Independence: The observations are independent of each other.\n",
        "3. Homoscedasticity: The variance of the errors is constant across all levels of x.\n",
        "4. Normality: The errors are normally distributed.\n",
        "\n",
        "If these assumptions are not met, alternative methods, such as robust regression or generalized linear models, may be more appropriate."
      ],
      "metadata": {
        "id": "COdjvDB9pZH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q7. How is the coefficient of determination (R²) interpreted in Simple Linear Regression?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "The coefficient of determination, denoted as R², is a statistical measure that indicates the proportion of the variance in the dependent variable (y) that is predictable from the independent variable (x) in a Simple Linear Regression model.\n",
        "\n",
        "Interpretation of R²:\n",
        "\n",
        "1. Proportion of explained variance: R² represents the proportion of the variance in y that is explained by the linear relationship with x. A high R² value indicates that the model explains a large proportion of the variance in y.\n",
        "2. Goodness of fit: R² measures the goodness of fit of the linear regression model. A high R² value indicates that the model fits the data well, while a low R² value indicates a poor fit.\n",
        "3. Predictive power: R² indicates the predictive power of the model. A high R² value suggests that the model can accurately predict y values based on x values.\n",
        "\n",
        "R² values range from 0 to 1, where:\n",
        "\n",
        "- R² = 0: The model explains none of the variance in y (i.e., the model is no better than a random guess).\n",
        "- R² = 1: The model explains all of the variance in y (i.e., the model is perfect).\n",
        "- 0 < R² < 1: The model explains some, but not all, of the variance in y.\n",
        "\n",
        "Common R² interpretation guidelines:\n",
        "\n",
        "- R² < 0.3: Weak relationship\n",
        "- 0.3 ≤ R² < 0.6: Moderate relationship\n",
        "- 0.6 ≤ R² < 0.8: Strong relationship\n",
        "- R² ≥ 0.8: Very strong relationship\n",
        "\n",
        " R² should be interpreted in conjunction with other diagnostic metrics, such as residual plots and hypothesis tests, to ensure that the model is valid and reliable.\n",
        "\n"
      ],
      "metadata": {
        "id": "s0ETCRsIpsiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Generate some sample data\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape((-1, 1))\n",
        "y = np.array([2, 3, 5, 7, 11])\n",
        "\n",
        "# Create and fit a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict y values\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Calculate R²\n",
        "r2 = r2_score(y, y_pred)\n",
        "print(f\"R²: {r2:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwnFF__NqMlP",
        "outputId": "8b03a4ce-bd84-46cc-9966-6654e5a9161e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R²: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q8. What is Multiple Linear Regression?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "Multiple Linear Regression (MLR) is a statistical technique used to model the relationship between a dependent variable (y) and multiple independent variables (x1, x2, ..., xn). It is an extension of Simple Linear Regression (SLR), where instead of one independent variable, multiple independent variables are used to predict the dependent variable.\n",
        "\n",
        "In MLR, the relationship between the dependent variable and independent variables is represented by the following equation:\n",
        "\n",
        "y = β0 + β1x1 + β2x2 + … + βnxn + ε\n",
        "\n",
        "Where:\n",
        "\n",
        "- y is the dependent variable\n",
        "- x1, x2, ..., xn are the independent variables\n",
        "- β0 is the intercept or constant term\n",
        "- β1, β2, ..., βn are the coefficients of the independent variables\n",
        "- ε is the error term, which represents the random variation in the dependent variable that is not explained by the independent variables.\n",
        "\n",
        "The goals of Multiple Linear Regression are:\n",
        "\n",
        "1. To identify the relationship between the dependent variable and multiple independent variables: MLR helps to understand how each independent variable affects the dependent variable, while controlling for the effects of other independent variables.\n",
        "2. To predict the value of the dependent variable: MLR can be used to predict the value of the dependent variable based on the values of the independent variables.\n",
        "3. To identify the most important independent variables: MLR can help to identify which independent variables have the most significant impact on the dependent variable.\n",
        "\n",
        "Assumptions of Multiple Linear Regression:\n",
        "\n",
        "1. **Linearity:** The relationship between the dependent variable and independent variables should be linear.\n",
        "2. **Independence:** Each observation should be independent of the others.\n",
        "3. **Homoscedasticity:** The variance of the error term should be constant across all levels of the independent variables.\n",
        "4. **Normality:** The error term should be normally distributed.\n",
        "5. **No multicollinearity:** The independent variables should not be highly correlated with each other.\n",
        "\n",
        "**Common applications of Multiple Linear Regression include:**\n",
        "\n",
        "1. **Predicting continuous outcomes:** MLR can be used to predict continuous outcomes, such as stock prices, temperatures, or energy consumption.\n",
        "2. **Analyzing the effect of multiple factors:** MLR can be used to analyze the effect of multiple factors on a dependent variable, such as the effect of temperature, humidity, and wind speed on energy consumption.\n",
        "3. **Identifying the most important factors:** MLR can be used to identify the most important factors that affect a dependent variable, such as identifying the most important factors that affect customer satisfaction."
      ],
      "metadata": {
        "id": "z3uhMcQhqnIL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q9: What is the main difference between Simple and Multiple Linear Regression?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "The main difference between Simple Linear Regression (SLR) and Multiple Linear Regression (MLR) is the number of independent variables used to predict the dependent variable.\n",
        "\n",
        "**Simple Linear Regression (SLR):**\n",
        "\n",
        "- Uses only one independent variable (x) to predict the dependent variable (y)\n",
        "- The relationship between x and y is modeled using a single linear equation: y = β0 + β1x + ε\n",
        "- SLR is used to analyze the relationship between two continuous variables\n",
        "\n",
        "**Multiple Linear Regression (MLR):**\n",
        "\n",
        "- Uses two or more independent variables (x1, x2, ..., xn) to predict the dependent variable (y)\n",
        "- The relationship between the independent variables and y is modeled using a linear equation: y = β0 + β1x1 + β2x2 + … + βnxn + ε\n",
        "- MLR is used to analyze the relationship between multiple independent variables and a continuous dependent variable\n",
        "\n",
        "Key differences:\n",
        "\n",
        "1. **Number of independent variables:** SLR uses one independent variable, while MLR uses two or more.\n",
        "2. **Complexity of the model:** MLR is a more complex model than SLR, as it involves more variables and interactions between them.\n",
        "3. **Interpretation of results:** In SLR, the coefficient β1 represents the change in y for a one-unit change in x. In MLR, each coefficient βi represents the change in y for a one-unit change in xi, while holding all other independent variables constant.\n",
        "4. **Assumptions:** MLR has additional assumptions compared to SLR, such as no multicollinearity between independent variables.\n",
        "\n",
        "When to use each:\n",
        "\n",
        "1. **SLR:** Use when you have a simple relationship between two continuous variables and want to analyze the relationship between them.\n",
        "2. **MLR:** Use when you have multiple independent variables that you want to analyze simultaneously to understand their relationships with the dependent variable."
      ],
      "metadata": {
        "id": "LOIvWx_mqxlM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q10. What are the key assumptions of Multiple Linear Regression?**\n",
        "\n",
        "**Answer:**\n",
        "Multiple Linear Regression (MLR) assumes the following:\n",
        "\n",
        "1. Linearity: The relationship between the dependent variable (y) and each independent variable (x) should be linear.\n",
        "2. Independence: Each observation should be independent of the others. This means that the errors (residuals) should not be correlated with each other.\n",
        "3. Homoscedasticity: The variance of the errors (residuals) should be constant across all levels of the independent variables.\n",
        "4. Normality: The errors (residuals) should be normally distributed. This can be checked using plots such as Q-Q plots or histograms.\n",
        "5. No multicollinearity: The independent variables should not be highly correlated with each other. This can be checked using correlation matrices or Variance Inflation Factor (VIF) scores.\n",
        "6. No auto-correlation: The errors (residuals) should not be auto-correlated, meaning that the errors at one observation should not be related to the errors at another observation.\n",
        "7. Constant variance: The variance of the errors (residuals) should be constant across all observations.\n",
        "8. No outliers: There should be no outliers in the data, as these can affect the estimates of the model parameters.\n",
        "9. No measurement error: The independent variables should be measured without error.\n",
        "\n",
        "If these assumptions are not met, it can lead to:\n",
        "\n",
        "- Biased or inconsistent estimates of the model parameters\n",
        "- Incorrect predictions\n",
        "- Inflated or deflated R-squared values\n",
        "- Incorrect conclusions about the relationships between the variables\n",
        "\n",
        "To check these assumptions, you can use various diagnostic plots and tests, such as:\n",
        "\n",
        "- Residual plots\n",
        "- Q-Q plots\n",
        "- Histograms\n",
        "- Correlation matrices\n",
        "- VIF scores\n",
        "- Durbin-Watson test\n",
        "- Breusch-Pagan test\n",
        "\n",
        "If the assumptions are not met, you may need to transform the data, use a different model, or employ techniques such as robust regression or generalized linear models."
      ],
      "metadata": {
        "id": "-YiyVZOmrsqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression mode?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "Heteroscedasticity is a statistical concept that refers to the phenomenon where the variance of the error term (residuals) in a regression model changes across different levels of the independent variable(s). In other words, the spread of the residuals is not constant across all levels of the independent variable(s).\n",
        "\n",
        "Heteroscedasticity can affect the results of a Multiple Linear Regression (MLR) model in several ways:\n",
        "\n",
        "1. **Inefficient estimates:** Heteroscedasticity can lead to inefficient estimates of the model parameters, which can result in incorrect predictions and conclusions.\n",
        "2. **Biased standard errors:** Heteroscedasticity can cause the standard errors of the model parameters to be biased, which can lead to incorrect inference and hypothesis testing.\n",
        "3. **Incorrect hypothesis testing:** Heteroscedasticity can affect the validity of hypothesis tests, such as the F-test and t-tests, which can lead to incorrect conclusions about the relationships between the variables.\n",
        "4. **Reduced model fit:** Heteroscedasticity can reduce the fit of the model, as measured by metrics such as R-squared, which can make it more difficult to identify meaningful relationships between the variables.\n",
        "\n",
        "**Types of heteroscedasticity:**\n",
        "\n",
        "1. **Positive heteroscedasticity:** The variance of the error term increases as the independent variable increases.\n",
        "2. **Negative heteroscedasticity:** The variance of the error term decreases as the independent variable increases.\n",
        "3. **Non-monotonic heteroscedasticity:** The variance of the error term changes in a non-monotonic way as the independent variable changes.\n",
        "\n",
        "**Detection of heteroscedasticity:**\n",
        "\n",
        "1. Visual inspection: Plot the residuals against the fitted values or the independent variable to check for non-constant variance.\n",
        "2. Breusch-Pagan test: A statistical test that can be used to detect heteroscedasticity.\n",
        "3. White test: A statistical test that can be used to detect heteroscedasticity.\n",
        "\n",
        "**Remedies for heteroscedasticity:**\n",
        "\n",
        "1. **Transformation of variables:** Transforming the variables can help to stabilize the variance.\n",
        "2. **Weighted least squares:** Using weighted least squares can help to reduce the impact of heteroscedasticity.\n",
        "3. **Robust standard errors:** Using robust standard errors can help to account for heteroscedasticity.\n",
        "4. **Generalized linear models:** Using generalized linear models can help to account for heteroscedasticity."
      ],
      "metadata": {
        "id": "USnwEty9r93-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q12. How can you improve a Multiple Linear Regression model with high multicollinearity?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "Multicollinearity occurs when two or more independent variables in a Multiple Linear Regression (MLR) model are highly correlated with each other. This can cause problems with the model, such as unstable estimates of the regression coefficients, inflated variance of the regression coefficients, and reduced accuracy of predictions.\n",
        "\n",
        "Here are some ways to improve an MLR model with high multicollinearity:\n",
        "\n",
        "1. **Remove highly correlated variables:** Identify the variables that are highly correlated with each other and remove one of them from the model. This can help reduce multicollinearity and improve the stability of the model.\n",
        "2. **Use dimensionality reduction techniques:** Techniques such as Principal Component Analysis (PCA) or Partial Least Squares (PLS) can be used to reduce the number of independent variables in the model while retaining most of the information.\n",
        "3. **Use regularization techniques:** Regularization techniques such as Ridge regression or Lasso regression can be used to reduce the impact of multicollinearity on the model.\n",
        "4. **Use a different model specification:** Consider using a different model specification, such as a generalized linear model or a generalized additive model, which may be less sensitive to multicollinearity.\n",
        "5. **Collect more data:** Collecting more data can help reduce multicollinearity by providing more information about the relationships between the variables.\n",
        "6. **Use a correlation matrix:** Use a correlation matrix to identify the variables that are highly correlated with each other and consider removing one of them from the model.\n",
        "7. **Use Variance Inflation Factor (VIF):** Use VIF to identify the variables that are highly correlated with each other and consider removing one of them from the model.\n",
        "8. **Use a stepwise regression:** Use a stepwise regression to select the most important variables in the model and remove the variables that are not significant."
      ],
      "metadata": {
        "id": "WHPdJNfMswQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Create a sample dataframe\n",
        "np.random.seed(0)\n",
        "df = pd.DataFrame({\n",
        "    'x1': np.random.rand(100),\n",
        "    'x2': np.random.rand(100),\n",
        "    'y': np.random.rand(100)\n",
        "})\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "df_scaled = scaler.fit_transform(df)\n",
        "\n",
        "# Perform PCA\n",
        "pca = PCA(n_components=2)\n",
        "df_pca = pca.fit_transform(df_scaled)\n",
        "\n",
        "# Fit the model\n",
        "model = LinearRegression()\n",
        "model.fit(df_pca[:, 0].reshape(-1, 1), df_pca[:, 1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "u1QAstrnulH-",
        "outputId": "55d7a942-46ec-4ac1-e029-dc650f435c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q13.What are some common techniques for transforming categorical variables for use in regression models?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "1. One-Hot Encoding (OHE)\n",
        "\n",
        "One-hot encoding is a technique where each category of the categorical variable is represented as a binary vector. For example, if we have a categorical variable \"color\" with three categories: \"red\", \"green\", and \"blue\", we can represent it as:\n",
        "\n",
        "| Color | Red | Green | Blue |\n",
        "| --- | --- | --- | --- |\n",
        "| Red   | 1   | 0     | 0    |\n",
        "| Green | 0   | 1     | 0    |\n",
        "| Blue  | 0   | 0     | 1    |\n",
        "\n",
        "2. Label Encoding\n",
        "\n",
        "Label encoding is a technique where each category of the categorical variable is assigned a unique integer value. For example:\n",
        "\n",
        "| Color | Label |\n",
        "| --- | --- |\n",
        "| Red   | 0    |\n",
        "| Green | 1    |\n",
        "| Blue  | 2    |\n",
        "\n",
        "3. Dummy Variables\n",
        "\n",
        "Dummy variables are similar to one-hot encoding, but we drop one category to avoid multicollinearity. For example:\n",
        "\n",
        "| Color | Red | Green |\n",
        "| --- | --- | --- |\n",
        "| Red   | 1   | 0     |\n",
        "| Green | 0   | 1     |\n",
        "| Blue  | 0   | 0     |\n",
        "\n",
        "4. Effect Coding\n",
        "\n",
        "Effect coding is a technique where each category of the categorical variable is represented as a vector of values that sum to zero. For example:\n",
        "\n",
        "| Color | Red | Green | Blue |\n",
        "| --- | --- | --- | --- |\n",
        "| Red   | 1   | 0     | -1   |\n",
        "| Green | 0   | 1     | -1   |\n",
        "| Blue  | -1  | -1    | 1    |\n",
        "\n",
        "5. Helmert Coding\n",
        "\n",
        "Helmert coding is a technique where each category of the categorical variable is represented as a vector of values that compare each category to the previous category. For example:\n",
        "\n",
        "| Color | Red | Green | Blue |\n",
        "| --- | --- | --- | --- |\n",
        "| Red   | 1   | 0     | 0    |\n",
        "| Green | -1/2 | 1     | 0    |\n",
        "| Blue  | -1/3 | -1/3  | 1    |\n",
        "\n"
      ],
      "metadata": {
        "id": "6p8W0gLKuq0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Create a sample dataframe\n",
        "df = pd.DataFrame({\n",
        "    'color': ['red', 'green', 'blue', 'red', 'green']\n",
        "})\n",
        "\n",
        "# One-hot encode the color column\n",
        "encoder = OneHotEncoder()\n",
        "encoded_data = encoder.fit_transform(df[['color']])\n",
        "\n",
        "# Convert the encoded data to a dataframe\n",
        "encoded_df = pd.DataFrame(encoded_data.toarray(), columns=encoder.get_feature_names_out())\n",
        "\n",
        "# Print the encoded dataframe\n",
        "print(encoded_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80587Zw9clf1",
        "outputId": "5c5377bc-eaab-4ce0-cd4f-d96a03c44b1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   color_blue  color_green  color_red\n",
            "0         0.0          0.0        1.0\n",
            "1         0.0          1.0        0.0\n",
            "2         1.0          0.0        0.0\n",
            "3         0.0          0.0        1.0\n",
            "4         0.0          1.0        0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q14.  What is the role of interaction terms in Multiple Linear Regression**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "Interaction terms in Multiple Linear Regression (MLR) play a crucial role in modeling the relationships between variables. An interaction term represents the joint effect of two or more independent variables on the dependent variable.\n",
        "\n",
        "**Role of interaction terms:**\n",
        "\n",
        "1. **Modeling complex relationships:** Interaction terms allow you to model complex relationships between variables, where the effect of one variable on the dependent variable depends on the level of another variable.\n",
        "2. **Capturing non-additive effects:** Interaction terms capture non-additive effects, where the combined effect of two or more variables is different from the sum of their individual effects.\n",
        "3. **Improving model fit:** Including interaction terms can improve the fit of the model, especially when there are significant interactions between variables.\n",
        "4. **Enhancing interpretability:** Interaction terms can provide insights into how variables interact with each other, which can be useful for understanding complex relationships.\n",
        "\n",
        "**Types of interaction terms:**\n",
        "\n",
        "1. **Two-way interactions:** Represent the joint effect of two independent variables on the dependent variable.\n",
        "2. **Three-way interactions:** Represent the joint effect of three independent variables on the dependent variable.\n",
        "3. **Higher-order interactions:** Represent the joint effect of four or more independent variables on the dependent variable.\n",
        "\n",
        "**When to include interaction terms:**\n",
        "\n",
        "1. **Theoretical justification:** Include interaction terms based on theoretical knowledge or prior research that suggests interactions between variables.\n",
        "2. **Significant interactions:** Include interaction terms if they are statistically significant, indicating that the interaction is meaningful.\n",
        "3. **Model improvement:** Include interaction terms if they improve the fit of the model, as measured by metrics such as R-squared or mean squared error.\n",
        "\n",
        "**Common issues with interaction terms:**\n",
        "\n",
        "1. **Multicollinearity:** Interaction terms can be highly correlated with the individual variables, leading to multicollinearity issues.\n",
        "2. **Overfitting:** Including too many interaction terms can lead to overfitting, especially if the sample size is small.\n",
        "3. **Interpretation challenges:** Interaction terms can be challenging to interpret, especially if there are multiple interactions involved.\n",
        "\n",
        "To address these issues, it's essential to:\n",
        "\n",
        "1. **Carefully select interaction terms:** Based on theoretical justification, statistical significance, and model improvement.\n",
        "2. **Use regularization techniques:** Such as L1 or L2 regularization to reduce multicollinearity and overfitting.\n",
        "3. **Use techniques for interpreting interactions:** Such as plotting interaction effects or using techniques like partial dependence plots.\n"
      ],
      "metadata": {
        "id": "4-WuQRO6c62R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Create a sample dataframe\n",
        "df = pd.DataFrame({\n",
        "    'x1': [1, 2, 3, 4, 5],\n",
        "    'x2': [2, 3, 4, 5, 6],\n",
        "    'y': [3, 5, 7, 9, 11]\n",
        "})\n",
        "\n",
        "# Create interaction terms using PolynomialFeatures\n",
        "poly_features = PolynomialFeatures(degree=2)\n",
        "interaction_terms = poly_features.fit_transform(df[['x1', 'x2']])\n",
        "\n",
        "# Create a new dataframe with the interaction terms\n",
        "df_interaction = pd.DataFrame(interaction_terms, columns=poly_features.get_feature_names_out())\n",
        "\n",
        "# Add the interaction terms to the original dataframe\n",
        "df = pd.concat([df, df_interaction], axis=1)\n",
        "\n",
        "# Fit a Multiple Linear Regression model with interaction terms\n",
        "model = LinearRegression()\n",
        "model.fit(df[['x1', 'x2', 'x1^2', 'x2^2', 'x1 x2']], df['y'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "BN8yf68zfT19",
        "outputId": "456ef5d3-b76e-45f0-a5a7-a45b305a88b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "The interpretation of the intercept can differ between Simple and Multiple Linear Regression due to the differences in the models and the relationships between the variables.\n",
        "\n",
        "####**Simple Linear Regression:**\n",
        "\n",
        "In Simple Linear Regression, the intercept represents the expected value of the dependent variable (y) when the independent variable (x) is equal to zero. This is because the model equation is:\n",
        "\n",
        "y = β0 + β1x + ε\n",
        "\n",
        "where β0 is the intercept, β1 is the slope, and ε is the error term.\n",
        "\n",
        "For example, if we have a simple linear regression model that predicts the relationship between the number of hours studied (x) and the exam score (y), the intercept might represent the expected exam score for a student who does not study at all (i.e., x = 0).\n",
        "\n",
        "####**Multiple Linear Regression:**\n",
        "\n",
        "In Multiple Linear Regression, the intercept represents the expected value of the dependent variable (y) when all the independent variables (x1, x2, ..., xn) are equal to zero. This is because the model equation is:\n",
        "\n",
        "y = β0 + β1x1 + β2x2 + … + βnxn + ε\n",
        "\n",
        "where β0 is the intercept, β1, β2, …, βn are the slopes, and ε is the error term.\n",
        "\n",
        "For example, if we have a multiple linear regression model that predicts the relationship between the number of hours studied (x1), the number of practice problems completed (x2), and the exam score (y), the intercept might represent the expected exam score for a student who does not study at all (i.e., x1 = 0) and does not complete any practice problems (i.e., x2 = 0).\n",
        "\n",
        "####**Key differences:**\n",
        "\n",
        "1. **Number of variables:** Simple Linear Regression has only one independent variable, while Multiple Linear Regression has multiple independent variables.\n",
        "2. **Intercept interpretation:** In Simple Linear Regression, the intercept represents the expected value of the dependent variable when the independent variable is equal to zero. In Multiple Linear Regression, the intercept represents the expected value of the dependent variable when all independent variables are equal to zero.\n",
        "3. **Relationship between variables:** Simple Linear Regression assumes a linear relationship between the independent variable and the dependent variable. Multiple Linear Regression assumes a linear relationship between each independent variable and the dependent variable, while controlling for the effects of other independent variables.\n",
        "\n",
        "In summary, the interpretation of the intercept differs between Simple and Multiple Linear Regression due to the differences in the models and the relationships between the variables."
      ],
      "metadata": {
        "id": "lV5sQ_xNgA4i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q16. What is the significance of the slope in regression analysis, and how does it affect predictions?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "The slope in regression analysis represents the change in the dependent variable (y) for a one-unit change in the independent variable (x), while holding all other independent variables constant. The slope is a measure of the strength and direction of the linear relationship between the variables.\n",
        "\n",
        "####**Significance of the slope:**\n",
        "\n",
        "1. **Direction of the relationship:** The sign of the slope (positive or negative) indicates the direction of the relationship between the variables.\n",
        "2. **Strength of the relationship:** The magnitude of the slope indicates the strength of the relationship between the variables.\n",
        "3. **Predictive power:** The slope is used to make predictions about the dependent variable based on the independent variable(s).\n",
        "\n",
        "####**Effects of the slope on predictions:**\n",
        "\n",
        "1. **Positive slope:** A positive slope indicates that as the independent variable increases, the dependent variable also increases. Predictions will be higher for higher values of the independent variable.\n",
        "2. **Negative slope:** A negative slope indicates that as the independent variable increases, the dependent variable decreases. Predictions will be lower for higher values of the independent variable.\n",
        "3. **Steep slope:** A steep slope indicates a strong relationship between the variables. Small changes in the independent variable will result in large changes in the dependent variable.\n",
        "4. **Shallow slope:** A shallow slope indicates a weak relationship between the variables. Large changes in the independent variable will result in small changes in the dependent variable.\n",
        "\n",
        "####**Interpretation of the slope:**\n",
        "\n",
        "1. **Unit change:** The slope represents the change in the dependent variable for a one-unit change in the independent variable.\n",
        "2. **Percentage change:** To interpret the slope as a percentage change, multiply the slope by 100.\n",
        "\n",
        "Example:\n",
        "\n",
        "Suppose we have a simple linear regression model that predicts the relationship between the number of hours studied (x) and the exam score (y). The slope of the model is 2.5.\n",
        "\n",
        "- **Interpretation:** For every additional hour studied, the exam score is expected to increase by 2.5 points.\n",
        "- **Prediction:** If a student studies for 5 hours, their predicted exam score would be 5 x 2.5 = 12.5 points higher than if they had not studied at all.\n"
      ],
      "metadata": {
        "id": "RT5fyb_8goTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q17. How does the intercept in a regression model provide context for the relationship between variables?**\n",
        "**Answer:**\n",
        "\n",
        "The intercept in a regression model provides context for the relationship between variables in several ways:\n",
        "\n",
        "####**Interpretation of the Intercept**\n",
        "\n",
        "1. **Starting point:** The intercept represents the expected value of the dependent variable when all independent variables are equal to zero. This provides a starting point for understanding the relationship between the variables.\n",
        "2. **Baseline value:** The intercept can be thought of as a baseline value for the dependent variable. It represents the value of the dependent variable when none of the independent variables are present.\n",
        "3. **Reference point:** The intercept serves as a reference point for evaluating the effects of the independent variables on the dependent variable.\n",
        "\n",
        "####**Context for the Relationship**\n",
        "\n",
        "1. **Direction of the relationship:** The intercept can indicate the direction of the relationship between the variables. A positive intercept suggests that the dependent variable tends to be positive even when the independent variables are zero.\n",
        "2. **Strength of the relationship:** The magnitude of the intercept can provide insight into the strength of the relationship between the variables. A large intercept may indicate a strong relationship.\n",
        "3. **Interactions between variables:** The intercept can be affected by interactions between independent variables. A significant intercept may indicate that the relationship between the variables is influenced by interactions.\n",
        "\n",
        "####**Practical Applications**\n",
        "\n",
        "1. **Predicting outcomes:** The intercept can be used to predict outcomes when all independent variables are zero. This can be useful in scenarios where the independent variables are not present or are not relevant.\n",
        "2. **Comparing models:** The intercept can be used to compare different models. A model with a larger intercept may indicate a stronger relationship between the variables.\n",
        "3. **Identifying anomalies:** A significant intercept can indicate anomalies or outliers in the data.\n",
        "\n"
      ],
      "metadata": {
        "id": "wZ61WLg-hnLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q18. What are the limitations of using R² as a sole measure of model performance?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "R² (R-squared or coefficient of determination) is a widely used metric to evaluate the performance of a regression model. However, relying solely on R² has several limitations:\n",
        "\n",
        "####**Limitations of R²**\n",
        "\n",
        "1. **Overfitting:** R² can be misleading when the model is overfitting. A high R² value does not necessarily mean the model is generalizing well.\n",
        "\n",
        "2. **Model Complexity:** R² does not account for model complexity. A more complex model with more parameters may have a higher R² value, but may not be the best choice.\n",
        "\n",
        "3. **Non-Normal Residuals:** R² assumes normality of residuals. If residuals are not normally distributed, R² may not accurately reflect model performance.\n",
        "\n",
        "4. **Non-Constant Variance:** R² assumes constant variance of residuals. If variance is not constant, R² may not accurately reflect model performance.\n",
        "\n",
        "5. **Lack of Interpretability:** R² is a relative measure, making it difficult to interpret in isolation. A high R² value may not necessarily mean the model is performing well in absolute terms.\n",
        "\n",
        "6. **Sensitivity to Outliers:** R² is sensitive to outliers, which can greatly impact the value.\n",
        "\n",
        "7. **Ignores Prediction Intervals:** R² only evaluates the model's ability to explain variance, not its ability to make accurate predictions with confidence intervals.\n",
        "\n",
        "####**Alternatives and Complementary Metrics**\n",
        "\n",
        "To address these limitations, consider using complementary metrics, such as:\n",
        "\n",
        "1. **Mean Absolute Error (MAE) or Mean Squared Error (MSE):** Evaluate the model's predictive accuracy.\n",
        "2. **Mean Absolute Percentage Error (MAPE):** Evaluate the model's predictive accuracy in percentage terms.\n",
        "3. **Root Mean Squared Percentage Error (RMSPE):** Evaluate the model's predictive accuracy in percentage terms.\n",
        "4. **Cross-Validation:** Evaluate the model's performance on unseen data.\n",
        "5. **Residual Plots:** Visualize the residuals to check for normality, constant variance, and outliers.\n",
        "\n",
        "By using a combination of these metrics, you can gain a more comprehensive understanding of your model's performance and limitations."
      ],
      "metadata": {
        "id": "voua7enNZJ4Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q19.  How would you interpret a large standard error for a regression coefficient?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "A large standard error for a regression coefficient indicates that the estimate of the coefficient is uncertain and may not be reliable. Here are some possible interpretations:\n",
        "\n",
        "1. **Imprecision in the estimate:**\n",
        "\n",
        " A large standard error means that the confidence interval for the coefficient is wide, indicating that the true value of the coefficient could be quite different from the estimated value.\n",
        "2. **High variability in the data:**\n",
        "\n",
        " A large standard error can be a sign of high variability in the data, making it difficult to estimate the coefficient precisely.\n",
        "3. **Multicollinearity:**\n",
        "\n",
        " If the independent variables are highly correlated with each other (multicollinearity), it can lead to large standard errors for the coefficients.\n",
        "4. **Overfitting:**\n",
        "\n",
        " A large standard error can be a sign of overfitting, where the model is too complex and fits the noise in the data rather than the underlying pattern.\n",
        "5. **Insufficient data:**\n",
        "\n",
        " A large standard error can also indicate that there is insufficient data to estimate the coefficient precisely.\n",
        "\n",
        "####**Consequences of a large standard error:**\n",
        "\n",
        "1. **Reduced confidence in the coefficient:** A large standard error reduces our confidence in the estimated value of the coefficient.\n",
        "2. **Wide confidence intervals:** The confidence intervals for the coefficient will be wide, making it difficult to determine the true value of the coefficient.\n",
        "3. **Difficulty in hypothesis testing:** A large standard error can make it difficult to perform hypothesis tests on the coefficient, as the test statistic may not be reliable.\n",
        "\n",
        "To address a large standard error, you can try:\n",
        "\n",
        "1. **Collecting more data:** Increasing the sample size can help reduce the standard error.\n",
        "2. **Reducing multicollinearity:** Using techniques such as dimensionality reduction or regularization can help reduce multicollinearity.\n",
        "3. **Simplifying the model:** Reducing the complexity of the model can help reduce overfitting and improve the precision of the estimates.\n",
        "4. **Using robust standard errors:** Using robust standard errors, such as Huber-White standard errors, can help account for heteroscedasticity and improve the accuracy of the estimates."
      ],
      "metadata": {
        "id": "CD6pi98Hbhq6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "Heteroscedasticity can be identified in residual plots by looking for the following patterns:\n",
        "\n",
        "####**Patterns Indicative of Heteroscedasticity**\n",
        "\n",
        "1. **Fanning or cone-shaped pattern:**\n",
        "\n",
        " The residuals spread out or fan out as the fitted values increase, indicating that the variance of the residuals increases with the level of the independent variable.\n",
        "2. **Non-random pattern:**\n",
        "\n",
        " The residuals display a non-random pattern, such as a curve or a wave, indicating that the variance of the residuals changes with the level of the independent variable.\n",
        "3. **Increasing or decreasing variance:** The variance of the residuals increases or decreases as the fitted values increase, indicating that the variance of the residuals is not constant.\n",
        "\n",
        "####**Importance of Addressing Heteroscedasticity**\n",
        "\n",
        "1. **Inaccurate inference:** Heteroscedasticity can lead to inaccurate inference and hypothesis testing, as the standard errors of the regression coefficients may be biased.\n",
        "2. **Poor predictions:** Heteroscedasticity can lead to poor predictions, as the model may not accurately capture the underlying relationship between the variables.\n",
        "3. **Model misspecification:** Heteroscedasticity can be a sign of model misspecification, indicating that the model is not capturing the underlying relationships between the variables.\n",
        "\n",
        "####**Methods to Address Heteroscedasticity**\n",
        "\n",
        "1. **Transformation of variables:** Transforming the variables, such as taking the logarithm or square root, can help stabilize the variance.\n",
        "2. **Weighted least squares:** Using weighted least squares can help account for heteroscedasticity by giving more weight to observations with lower variance.\n",
        "3. **Robust standard errors:** Using robust standard errors, such as Huber-White standard errors, can help account for heteroscedasticity and provide more accurate inference.\n",
        "4. **Generalized linear models:** Using generalized linear models, such as the generalized linear model with a non-constant variance function, can help account for heteroscedasticity."
      ],
      "metadata": {
        "id": "EWS5KypZc1k8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q21. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "\n",
        "If a Multiple Linear Regression (MLR) model has a high R² but low adjusted R², it may indicate the following:\n",
        "\n",
        "High R²:\n",
        "\n",
        "1. **Good fit:** The model is fitting the data well, and the independent variables are explaining a significant amount of variation in the dependent variable.\n",
        "2. **Overfitting:** The model may be overfitting the data, meaning it is fitting the noise in the data rather than the underlying pattern.\n",
        "\n",
        "Low Adjusted R²:\n",
        "\n",
        "1. **Penalty for complexity:** The adjusted R² penalizes the model for its complexity, which means that the model may have too many independent variables or interactions.\n",
        "2. **Inadequate explanatory power:** The adjusted R² suggests that the model's explanatory power is not sufficient, considering the number of independent variables and the sample size.\n",
        "\n",
        "Possible causes:\n",
        "\n",
        "1. **Overfitting:** The model may be overfitting the data, which can lead to a high R² but low adjusted R².\n",
        "2. **Multicollinearity:** High correlation between independent variables can lead to unstable estimates and a low adjusted R².\n",
        "3. **Irrelevant variables:** Including irrelevant or redundant independent variables can decrease the adjusted R².\n",
        "4. **Sample size:** A small sample size can lead to a low adjusted R², even if the R² is high.\n",
        "\n",
        "**Actions to take:**\n",
        "\n",
        "1. **Simplify the model:** Remove irrelevant or redundant independent variables to improve the adjusted R².\n",
        "2. **Regularization techniques:** Use regularization techniques, such as Lasso or Ridge regression, to reduce overfitting and improve the adjusted R².\n",
        "3. **Cross-validation:** Use cross-validation to evaluate the model's performance on unseen data and avoid overfitting.\n",
        "4. **Collect more data:** Increase the sample size to improve the accuracy and reliability of the model.\n",
        "\n",
        "By addressing these issues, one can improve the adjusted R² and increase the confidence in your MLR model.\n"
      ],
      "metadata": {
        "id": "RPv15BrYfRFD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q22. Why is it important to scale variables in Multiple Linear Regression?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "Scaling variables in Multiple Linear Regression (MLR) is important for several reasons:\n",
        "\n",
        "Reasons for Scaling Variables\n",
        "\n",
        "1. Prevents Feature Dominance\n",
        "Scaling variables prevents features with large ranges from dominating the model. Without scaling, the model may give more weight to features with larger ranges, leading to biased results.\n",
        "\n",
        "2. Improves Model Interpretability\n",
        "Scaling variables makes it easier to interpret the model's coefficients. When all variables are on the same scale, the coefficients represent the change in the response variable for a one-unit change in the predictor variable.\n",
        "\n",
        "3. Enhances Numerical Stability\n",
        "Scaling variables improves numerical stability by reducing the risk of overflow or underflow errors. This is particularly important when working with large datasets or using algorithms that involve matrix operations.\n",
        "\n",
        "4. Facilitates Model Selection and Hyperparameter Tuning\n",
        "Scaling variables makes it easier to compare models with different sets of features or hyperparameters. This is because the scaled variables are on the same footing, allowing for more accurate comparisons.\n",
        "\n",
        "5. Supports Regularization Techniques\n",
        "Scaling variables is essential when using regularization techniques, such as Lasso or Ridge regression. These techniques rely on the variables being on the same scale to effectively penalize large coefficients.\n",
        "\n",
        "Common Scaling Techniques\n",
        "\n",
        "1. **Standardization:** Subtracting the mean and dividing by the standard deviation for each variable.\n",
        "2. **Normalization:** Scaling variables to a common range, usually between 0 and 1.\n",
        "3. **Log Scaling:** Taking the logarithm of each variable to reduce skewness and improve normality.\n",
        "\n",
        "By scaling variables in MLR, you can improve the accuracy, interpretability, and reliability of your models."
      ],
      "metadata": {
        "id": "xxHB1eHSvfc2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q23. What is polynomial regression?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "Polynomial regression is a type of regression analysis in which the relationship between the independent variable(s) and the dependent variable is modeled using a polynomial equation.\n",
        "\n",
        "Polynomial Equation\n",
        "\n",
        "A polynomial equation is an equation of the form:\n",
        "\n",
        "y = β0 + β1x + β2x² + β3x³ + … + βnx^n + ε\n",
        "\n",
        "where:\n",
        "\n",
        "- y is the dependent variable\n",
        "- x is the independent variable\n",
        "- β0, β1, β2, …, βn are the coefficients of the polynomial equation\n",
        "- n is the degree of the polynomial equation\n",
        "- ε is the error term\n",
        "\n",
        "Types of Polynomial Regression\n",
        "\n",
        "1. **Linear Regression:** A polynomial regression with a degree of 1.\n",
        "2. **Quadratic Regression:** A polynomial regression with a degree of 2.\n",
        "3. **Cubic Regression:** A polynomial regression with a degree of 3.\n",
        "4. **Higher-Order Polynomial Regression:** A polynomial regression with a degree greater than 3.\n",
        "\n",
        "Advantages of Polynomial Regression\n",
        "\n",
        "1. **Flexibility:** Polynomial regression can model complex relationships between variables.\n",
        "2. **Improved Fit:** Polynomial regression can provide a better fit to the data than linear regression.\n",
        "3. **Easy to Interpret:** Polynomial regression coefficients can be interpreted similarly to linear regression coefficients.\n",
        "\n",
        "Disadvantages of Polynomial Regression\n",
        "\n",
        "1. **Overfitting:** Polynomial regression can suffer from overfitting, especially with high-degree polynomials.\n",
        "2. **Multicollinearity:** Polynomial regression can suffer from multicollinearity, especially when using high-degree polynomials.\n",
        "3. **Difficulty in Model Selection:** Choosing the correct degree of the polynomial can be challenging.\n",
        "\n",
        "Common Applications of Polynomial Regression\n",
        "\n",
        "1. **Predicting Non-Linear Relationships:** Polynomial regression is useful for predicting non-linear relationships between variables.\n",
        "2. **Modeling Complex Systems:** Polynomial regression is useful for modeling complex systems, such as population growth or chemical reactions.\n",
        "3. **Data Analysis:** Polynomial regression is useful for data analysis, especially when the relationship between variables is non-linear."
      ],
      "metadata": {
        "id": "ZfsBApQ-wFZv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q24. How does polynomial regression differ from linear regression?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "Polynomial regression and linear regression are both types of regression analysis, but they differ in several key ways:\n",
        "\n",
        "Differences Between Polynomial Regression and Linear Regression\n",
        "\n",
        "1. **Model Form**\n",
        "\n",
        "- Linear Regression: y = β0 + β1x + ε (straight line)\n",
        "- Polynomial Regression: y = β0 + β1x + β2x² + … + βnx^n + ε (curved line)\n",
        "\n",
        "2. **Relationship Between Variables**\n",
        "\n",
        "- Linear Regression: Assumes a linear relationship between the independent variable(s) and the dependent variable.\n",
        "- Polynomial Regression: Assumes a non-linear relationship between the independent variable(s) and the dependent variable.\n",
        "\n",
        "3. **Degree of Polynomial**\n",
        "\n",
        "- Linear Regression: Degree of polynomial is 1 (straight line).\n",
        "- Polynomial Regression: Degree of polynomial can be 2 or higher (curved line).\n",
        "\n",
        "4. **Complexity of Model**\n",
        "\n",
        "- Linear Regression: Simplest form of regression analysis.\n",
        "- Polynomial Regression: More complex than linear regression, especially with higher-degree polynomials.\n",
        "\n",
        "5. **Interpretation of Coefficients**\n",
        "\n",
        "- Linear Regression: Coefficients represent the change in the dependent variable for a one-unit change in the independent variable.\n",
        "- Polynomial Regression: Coefficients represent the change in the dependent variable for a one-unit change in the independent variable, but the interpretation is more complex due to the non-linear relationship.\n",
        "\n",
        "6. **Risk of Overfitting**\n",
        "\n",
        "- Linear Regression: Less risk of overfitting due to the simplicity of the model.\n",
        "- Polynomial Regression: Higher risk of overfitting, especially with higher-degree polynomials.\n",
        "\n",
        "7. **Computational Complexity**\n",
        "\n",
        "- Linear Regression: Computationally simple.\n",
        "- Polynomial Regression: Computationally more complex, especially with higher-degree polynomials.\n",
        "\n",
        "Choosing Between Polynomial Regression and Linear Regression\n",
        "\n",
        "1. Use Linear Regression: When the relationship between the variables is linear, and the goal is to model a simple relationship.\n",
        "2. Use Polynomial Regression: When the relationship between the variables is non-linear, and the goal is to model a more complex relationship.\n",
        "\n",
        "Ultimately, the choice between polynomial regression and linear regression depends on the nature of the relationship between the variables and the goals of the analysis.\n"
      ],
      "metadata": {
        "id": "KofjvCPmw6qm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q25. When is polynomial regression used?**\n",
        "**Answer:**\n",
        "\n",
        "Polynomial regression is used in a variety of situations, including:\n",
        "\n",
        "When to Use Polynomial Regression\n",
        "\n",
        "1. **Non-linear relationships:** When the relationship between the independent variable(s) and the dependent variable is non-linear, polynomial regression can be used to model the relationship.\n",
        "2. **Curvilinear relationships:** When the relationship between the variables is curvilinear, polynomial regression can be used to model the relationship.\n",
        "3. **Complex systems:** When modeling complex systems, such as population growth or chemical reactions, polynomial regression can be used to capture the underlying dynamics.\n",
        "4. **Data with outliers:** When the data contains outliers, polynomial regression can be used to model the relationship while reducing the impact of the outliers.\n",
        "5. **Modeling seasonal data:** Polynomial regression can be used to model seasonal data, such as temperature or sales data, where the relationship between the variables changes over time.\n",
        "6. **Predicting continuous outcomes:** Polynomial regression can be used to predict continuous outcomes, such as stock prices or energy consumption.\n",
        "7. **Modeling dose-response relationships:** Polynomial regression can be used to model dose-response relationships in fields such as pharmacology or toxicology.\n",
        "\n",
        "Industries and Applications\n",
        "\n",
        "1. **Finance:** Polynomial regression is used in finance to model stock prices, predict portfolio performance, and estimate risk.\n",
        "2. **Marketing:** Polynomial regression is used in marketing to model customer behavior, predict sales, and estimate the effectiveness of marketing campaigns.\n",
        "3. **Engineering:** Polynomial regression is used in engineering to model complex systems, predict performance, and optimize design.\n",
        "4. **Environmental science:** Polynomial regression is used in environmental science to model climate patterns, predict weather events, and estimate the impact of environmental changes.\n",
        "5. **Healthcare:** Polynomial regression is used in healthcare to model disease progression, predict patient outcomes, and estimate the effectiveness of treatments."
      ],
      "metadata": {
        "id": "WiNoh7nrxFDL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q26. What is the general equation for polynomial regression?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "The general equation for polynomial regression is:\n",
        "\n",
        "y = β0 + β1x + β2x² + β3x³ + … + βnx^n + ε\n",
        "\n",
        "where:\n",
        "\n",
        "- y is the dependent variable (response variable)\n",
        "- x is the independent variable (predictor variable)\n",
        "- β0, β1, β2, …, βn are the coefficients of the polynomial equation\n",
        "- n is the degree of the polynomial equation (e.g., linear, quadratic, cubic, etc.)\n",
        "- ε is the error term (residual)\n",
        "\n",
        "This equation can be expanded to include multiple independent variables, interactions between variables, and other terms.\n",
        "\n",
        "Linear Polynomial Regression (Degree 1):\n",
        "\n",
        "y = β0 + β1x + ε\n",
        "\n",
        "Quadratic Polynomial Regression (Degree 2):\n",
        "\n",
        "y = β0 + β1x + β2x² + ε\n",
        "\n",
        "Cubic Polynomial Regression (Degree 3):\n",
        "\n",
        "y = β0 + β1x + β2x² + β3x³ + ε\n",
        "\n",
        "And so on.\n"
      ],
      "metadata": {
        "id": "v6rrqR1T2ZLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q27. Can polynomial regression be applied to multiple variables?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "Yes, polynomial regression can be applied to multiple variables. This is known as multivariate polynomial regression.\n",
        "\n",
        "Multivariate Polynomial Regression\n",
        "\n",
        "In multivariate polynomial regression, the dependent variable (y) is modeled as a function of multiple independent variables (x1, x2, ..., xn) using a polynomial equation.\n",
        "\n",
        "The general equation for multivariate polynomial regression is:\n",
        "\n",
        "y = β0 + β11x1 + β12x1² + … + β1nx1^n + β21x2 + β22x2² + … + β2nx2^n + … + βn1xn + βn2xn² + … + βnnxn^n + ε\n",
        "\n",
        "where:\n",
        "\n",
        "- y is the dependent variable\n",
        "- x1, x2, ..., xn are the independent variables\n",
        "- β0, β11, β12, …, βnn are the coefficients of the polynomial equation\n",
        "- n is the degree of the polynomial equation\n",
        "- ε is the error term\n",
        "\n",
        "Types of Multivariate Polynomial Regression\n",
        "\n",
        "1. **First-order multivariate polynomial regression:** Includes only linear terms for each independent variable.\n",
        "2. **Second-order multivariate polynomial regression:** Includes linear and quadratic terms for each independent variable.\n",
        "3. **Higher-order multivariate polynomial regression:** Includes linear, quadratic, and higher-order terms for each independent variable.\n",
        "\n",
        "Advantages of Multivariate Polynomial Regression\n",
        "\n",
        "1. **Can model complex relationships:** Multivariate polynomial regression can model complex relationships between multiple independent variables and the dependent variable.\n",
        "2. **Can handle non-linear relationships:** Multivariate polynomial regression can handle non-linear relationships between the independent variables and the dependent variable.\n",
        "3. **Can provide insights into interactions:** Multivariate polynomial regression can provide insights into interactions between independent variables.\n",
        "\n",
        "Challenges of Multivariate Polynomial Regression\n",
        "\n",
        "1. **Risk of overfitting:** Multivariate polynomial regression can suffer from overfitting, especially when using high-degree polynomials.\n",
        "2. **Computational complexity:** Multivariate polynomial regression can be computationally complex, especially when dealing with large datasets.\n",
        "3. **Interpretation of coefficients:** Multivariate polynomial regression coefficients can be difficult to interpret, especially when dealing with high-degree polynomials."
      ],
      "metadata": {
        "id": "eFQRXk3b91if"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q28. What are the limitations of polynomial regression?**\n",
        "\n",
        "**Answer:**\n",
        "Polynomial regression has several limitations:\n",
        "\n",
        "Limitations of Polynomial Regression\n",
        "\n",
        "1. **Overfitting**\n",
        "\n",
        "Polynomial regression can easily overfit the data, especially when using high-degree polynomials. Overfitting occurs when the model is too complex and fits the noise in the data rather than the underlying pattern.\n",
        "\n",
        "2. **Multicollinearity**\n",
        "\n",
        "Polynomial regression can suffer from multicollinearity, especially when using high-degree polynomials. Multicollinearity occurs when the independent variables are highly correlated with each other, leading to unstable estimates of the coefficients.\n",
        "\n",
        "3. **Computational Complexity**\n",
        "\n",
        "Polynomial regression can be computationally complex, especially when dealing with large datasets or high-degree polynomials. This can lead to increased computational time and memory requirements.\n",
        "\n",
        "4. **Difficulty in Model Selection**\n",
        "\n",
        "Choosing the correct degree of the polynomial can be challenging, especially when dealing with complex data. A high-degree polynomial may overfit the data, while a low-degree polynomial may underfit the data.\n",
        "\n",
        "5. **Interpretation of Coefficients**\n",
        "\n",
        "Polynomial regression coefficients can be difficult to interpret, especially when dealing with high-degree polynomials. The coefficients may not have a clear physical meaning, making it challenging to understand the relationships between the variables.\n",
        "\n",
        "6. **Non-Robustness to Outliers**\n",
        "\n",
        "Polynomial regression can be sensitive to outliers in the data. Outliers can greatly impact the estimates of the coefficients, leading to inaccurate predictions.\n",
        "\n",
        "7. **Limited Generalizability**\n",
        "\n",
        "Polynomial regression models may not generalize well to new, unseen data. The model may be too specialized to the training data and may not capture the underlying patterns in the data.\n",
        "\n",
        "8. **Difficulty in Handling Non-Numeric Data**\n",
        "\n",
        "Polynomial regression can be challenging to apply to non-numeric data, such as categorical or text data. The model requires numeric inputs, which can limit its applicability to certain types of data.\n"
      ],
      "metadata": {
        "id": "mYJsDnCA-0pk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "When selecting the degree of a polynomial, several methods can be used to evaluate model fit:\n",
        "\n",
        "Methods to Evaluate Model Fit\n",
        "\n",
        "1. **Coefficient of Determination (R²):** Measures the proportion of variance in the dependent variable that is explained by the polynomial model. A higher R² value indicates a better fit.\n",
        "2. **Mean Squared Error (MSE):** Measures the average squared difference between predicted and actual values. A lower MSE value indicates a better fit.\n",
        "3. **Mean Absolute Error (MAE):** Measures the average absolute difference between predicted and actual values. A lower MAE value indicates a better fit.\n",
        "4. **Cross-Validation:** Involves splitting the data into training and testing sets, fitting the model to the training set, and evaluating its performance on the testing set. This helps to prevent overfitting.\n",
        "5. **Akaike Information Criterion (AIC):** Measures the relative quality of a model for a given set of data. A lower AIC value indicates a better fit.\n",
        "6. **Bayesian Information Criterion (BIC):** Similar to AIC, but with a stronger penalty for complex models. A lower BIC value indicates a better fit.\n",
        "7. **F-Statistic:** Measures the ratio of the variance explained by the model to the variance of the residuals. A higher F-statistic value indicates a better fit.\n",
        "8. **Residual Plots:** Visualize the residuals to check for patterns, outliers, or non-normality. A random scatter of residuals around the horizontal axis indicates a good fit.\n",
        "9. **Q-Q Plots:** Compare the distribution of residuals to a normal distribution. A good fit is indicated by a straight line.\n",
        "\n",
        "Degree Selection Methods\n",
        "\n",
        "1. **Forward Selection:** Start with a low-degree polynomial and add higher-degree terms until the fit improves.\n",
        "2. **Backward Elimination:** Start with a high-degree polynomial and remove lower-degree terms until the fit deteriorates.\n",
        "3. **Stepwise Regression:** Combine forward selection and backward elimination to select the optimal degree.\n",
        "\n",
        "By using these methods, you can evaluate the fit of polynomial models with different degrees and select the one that best balances complexity and accuracy."
      ],
      "metadata": {
        "id": "I71K0gPs_Xo5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q30. Why is visualization important in polynomial regression?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "Visualization is important in polynomial regression for several reasons:\n",
        "\n",
        "Reasons for Visualization in Polynomial Regression\n",
        "\n",
        "1. **Understanding Relationships:** Visualization helps to understand the relationships between the independent variable(s) and the dependent variable, including non-linear relationships.\n",
        "2. **Model Evaluation:** Visualization is essential for evaluating the fit of the polynomial model, including checking for overfitting, underfitting, and outliers.\n",
        "3. **Identifying Patterns:** Visualization can help identify patterns in the residuals, such as non-randomness, non-normality, or heteroscedasticity.\n",
        "4. **Communicating Results:** Visualization is an effective way to communicate the results of polynomial regression to non-technical stakeholders, including the relationships between variables and the fit of the model.\n",
        "\n",
        "Types of Visualizations for Polynomial Regression\n",
        "\n",
        "1. **Scatter Plots:** Visualize the relationship between the independent variable(s) and the dependent variable.\n",
        "2. **Residual Plots:** Visualize the residuals to check for patterns, outliers, or non-normality.\n",
        "3. **Q-Q Plots:** Compare the distribution of residuals to a normal distribution.\n",
        "4. **Polynomial Fit Plots:** Visualize the fitted polynomial curve to understand the relationship between the independent variable(s) and the dependent variable.\n",
        "5. **Partial Residual Plots:** Visualize the relationship between a specific independent variable and the dependent variable, while controlling for other independent variables.\n",
        "\n",
        "Benefits of Visualization in Polynomial Regression\n",
        "\n",
        "1. **Improved Understanding:** Visualization improves understanding of the relationships between variables and the fit of the model.\n",
        "2. **Better Model Evaluation:** Visualization helps to evaluate the fit of the model and identify areas for improvement.\n",
        "3. **Effective Communication:** Visualization communicates the results of polynomial regression in a clear and concise manner.\n",
        "4. **Increased Accuracy:** Visualization helps to identify and correct errors in the model, leading to increased accuracy."
      ],
      "metadata": {
        "id": "lbazGwz9_8dL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q31. How is polynomial regression implemented in Python?**\n",
        "**Answer:**\n",
        "\n"
      ],
      "metadata": {
        "id": "fQxmBq3cBUcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate sample data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 1)\n",
        "y = 3 * X**2 + 2 * X + np.random.randn(100, 1)\n",
        "\n",
        "# Create a polynomial regression model\n",
        "model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
        "\n",
        "# Fit the model to the data\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Plot the data and the fitted curve\n",
        "plt.scatter(X, y, label='Data')\n",
        "plt.plot(X, y_pred, label='Fitted curve', color='red')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "EKJ1psuGBtI6",
        "outputId": "8e01f038-0f68-4092-be4b-6c75010c5d03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}